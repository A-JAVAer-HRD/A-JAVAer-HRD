<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>分布式复习提升 | Huang Blog</title><meta name="author" content="Huang RD"><meta name="copyright" content="Huang RD"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="分布式复习提升一、理论、算法、协议1、CAP 理论简介CAP 也就是 Consistency（一致性）、Availability（可用性）、Partition Tolerance（分区容错性） 这三个单词首字母组合。  CAP 定理（CAP theorem）指出对于一个分布式系统来说，当设计读写操作时，只能同时满足以下三点中的两个：  一致性（Consistency） : 所有节点访问同一份最新的">
<meta property="og:type" content="article">
<meta property="og:title" content="分布式复习提升">
<meta property="og:url" content="http://www.haungrd.top/2023/06/01/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/index.html">
<meta property="og:site_name" content="Huang Blog">
<meta property="og:description" content="分布式复习提升一、理论、算法、协议1、CAP 理论简介CAP 也就是 Consistency（一致性）、Availability（可用性）、Partition Tolerance（分区容错性） 这三个单词首字母组合。  CAP 定理（CAP theorem）指出对于一个分布式系统来说，当设计读写操作时，只能同时满足以下三点中的两个：  一致性（Consistency） : 所有节点访问同一份最新的">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.huangrd.top/images/agentina/4.jpg">
<meta property="article:published_time" content="2023-06-01T04:12:57.000Z">
<meta property="article:modified_time" content="2023-06-13T11:09:52.352Z">
<meta property="article:author" content="Huang RD">
<meta property="article:tag" content="分布式">
<meta property="article:tag" content="分布式理论">
<meta property="article:tag" content="分布式ID">
<meta property="article:tag" content="分布式锁">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.huangrd.top/images/agentina/4.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://www.haungrd.top/2023/06/01/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '分布式复习提升',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-06-13 19:09:52'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://getwallpapers.com/wallpaper/full/a/1/8/1057222-free-download-cool-nature-backgrounds-1920x1200-windows-10.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">60</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">83</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">18</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://www.huangrd.top/images/agentina/4.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Huang Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">分布式复习提升</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-01T04:12:57.000Z" title="发表于 2023-06-01 12:12:57">2023-06-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-06-13T11:09:52.352Z" title="更新于 2023-06-13 19:09:52">2023-06-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/">微服务</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">13.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>43分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="分布式复习提升"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="分布式复习提升"><a href="#分布式复习提升" class="headerlink" title="分布式复习提升"></a>分布式复习提升</h1><h2 id="一、理论、算法、协议"><a href="#一、理论、算法、协议" class="headerlink" title="一、理论、算法、协议"></a>一、理论、算法、协议</h2><h3 id="1、CAP-理论"><a href="#1、CAP-理论" class="headerlink" title="1、CAP 理论"></a>1、CAP 理论</h3><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p><strong>CAP</strong> 也就是 <strong>Consistency（一致性）</strong>、<strong>Availability（可用性）</strong>、<strong>Partition Tolerance（分区容错性）</strong> 这三个单词首字母组合。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/cap.png" alt="img"></p>
<p>CAP 定理（CAP theorem）指出对于一个分布式系统来说，当设计读写操作时，只能同时满足以下三点中的两个：</p>
<ul>
<li><strong>一致性（Consistency）</strong> : 所有节点访问同一份最新的数据副本</li>
<li><strong>可用性（Availability）</strong>: 非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）。</li>
<li><strong>分区容错性（Partition Tolerance）</strong> : 分布式系统出现网络分区的时候，仍然能够对外提供服务。</li>
</ul>
<p><strong>什么是网络分区？</strong></p>
<p>分布式系统中，多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫 <strong>网络分区</strong>。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/partition-tolerance.png" alt="partition-tolerance"></p>
<p><strong>当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。</strong></p>
<p>简而言之就是：CAP 理论中分区容错性 P 是一定要满足的，在此基础上，只能满足可用性 A 或者一致性 C。</p>
<p>因此，<strong>分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构。</strong> 比如 Zookeeper、HBase 就是 CP 架构，Cassandra、Eureka 就是 AP 架构，Nacos 不仅支持 CP 架构也支持 AP 架构。</p>
<p><strong>为什么不可能选择 CA 架构呢？</strong> 举个例子：若系统出现“分区”，系统中的某个节点在进行写操作。为了保证 C， 必须要禁止其他节点的读写操作，这就和 A 发生冲突了。如果为了保证 A，其他节点的读写操作正常的话，那就和 C 发生冲突了。</p>
<p><strong>选择 CP 还是 AP 的关键在于当前的业务场景，没有定论，比如对于需要确保强一致性的场景如银行一般会选择保证 CP 。</strong></p>
<p>另外，需要补充说明的一点是： 如果网络分区正常的话（系统在绝大部分时候所处的状态），也就说不需要保证 P 的时候，C 和 A 能够同时保证。</p>
<h4 id="CAP-实际应用案例"><a href="#CAP-实际应用案例" class="headerlink" title="CAP 实际应用案例"></a>CAP 实际应用案例</h4><p>根据 Dubbo 的架构图。<strong>注册中心 Registry 在其中扮演了什么角色呢？提供了什么服务呢？</strong></p>
<p>注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/dubbo-architecture.png" alt="img"></p>
<p>常见的可以作为注册中心的组件有：ZooKeeper、Eureka、Nacos…。</p>
<ol>
<li><strong>ZooKeeper 保证的是 CP。</strong> 任何时刻对 ZooKeeper 的读请求都能得到一致性的结果，但是， ZooKeeper 不保证每次请求的可用性比如在 Leader 选举过程中或者半数以上的机器不可用的时候服务就是不可用的。</li>
<li><strong>Eureka 保证的则是 AP。</strong> Eureka 在设计的时候就是优先保证 A （可用性）。在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的。因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。 Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了。只不过这个节点上的数据可能并不是最新的。</li>
<li><strong>Nacos 不仅支持 CP 也支持 AP。</strong></li>
</ol>
<h3 id="2、Base-理论"><a href="#2、Base-理论" class="headerlink" title="2、Base 理论"></a>2、Base 理论</h3><h4 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h4><p><strong>BASE</strong> 是 <strong>Basically Available（基本可用）</strong> 、<strong>Soft-state（软状态）</strong> 和 <strong>Eventually Consistent（最终一致性）</strong> 三个短语的缩写。BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求。</p>
<h4 id="BASE-理论的核心思想"><a href="#BASE-理论的核心思想" class="headerlink" title="BASE 理论的核心思想"></a>BASE 理论的核心思想</h4><p>即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到<code>最终一致性</code>。</p>
<blockquote>
<p>也就是牺牲数据的一致性来满足系统的高可用性，系统中一部分数据不可用或者不一致时，仍需要保持系统整体“主要可用”。</p>
</blockquote>
<p><strong>BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充。</strong></p>
<h4 id="BASE-理论三要素"><a href="#BASE-理论三要素" class="headerlink" title="BASE 理论三要素"></a>BASE 理论三要素</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/format,png.png" alt="BASE理论三要素"></p>
<p><strong>基本可用</strong></p>
<p>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。</p>
<p><strong>允许损失部分可用性</strong>:</p>
<ul>
<li><strong>响应时间上的损失</strong>: 正常情况下，处理用户请求需要 0.5 s 返回结果，但是由于系统出现故障，处理用户请求的时间变为 3 s。</li>
<li><strong>系统功能上的损失</strong>：正常情况下，用户可以使用系统的全部功能，但是由于系统访问量突然剧增，系统的部分非核心功能无法使用。</li>
</ul>
<p><strong>软状态</strong></p>
<p>软状态指允许系统中的数据存在中间状态（<strong>CAP 理论中的数据不一致</strong>），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</p>
<p><strong>最终一致性</strong></p>
<p>最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。</p>
<blockquote>
<p>分布式一致性的 3 种级别：</p>
<ol>
<li><strong>强一致性</strong> ：系统写入了什么，读出来的就是什么。</li>
<li><strong>弱一致性</strong> ：不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态。</li>
<li><strong>最终一致性</strong> ：弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态。</li>
</ol>
<p><strong>业界比较推崇是最终一致性级别，但是某些对数据一致要求十分严格的场景比如银行转账还是要保证强一致性。</strong></p>
</blockquote>
<p>实现最终一致性的具体方式</p>
<blockquote>
<ol>
<li><strong>读时修复</strong> : 在读取数据时，检测数据的不一致，进行修复。比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点的副本数据不一致，系统就自动修复数据。</li>
<li><strong>写时修复</strong> : 在写入数据，检测数据的不一致时，进行修复。比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败 就将数据缓存下来，然后定时重传，修复数据的不一致性。</li>
<li><strong>异步修复</strong> : 这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复。</li>
</ol>
</blockquote>
<p>推荐 <strong>写时修复</strong>，这种方式对性能消耗比较低。</p>
<p><strong>ACID 是数据库事务完整性的理论，CAP 是分布式系统设计理论，BASE 是 CAP 理论中 AP 方案的延伸。</strong></p>
<h3 id="3、Paxos-算法"><a href="#3、Paxos-算法" class="headerlink" title="3、Paxos 算法"></a>3、Paxos 算法</h3><h4 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h4><p>Paxos 算法是第一个被证明完备的分布式系统共识算法。共识算法的作用是让分布式系统中的多个节点之间对某个提案（Proposal）达成一致的看法。提案的含义在分布式系统中十分宽泛，像哪一个节点是 Leader 节点、多个事件发生的顺序等等都可以是一个提案。</p>
<p>Paxos 算法主要包含 2 个部分:</p>
<ul>
<li><strong>Basic Paxos 算法</strong> ： 描述的是多节点之间如何就某个值(提案 Value)达成共识。</li>
<li><strong>Multi-Paxos 思想</strong> ： 描述的是执行多个 Basic Paxos 实例，就一系列值达成共识。Multi-Paxos 说白了就是执行多次 Basic Paxos ，核心还是 Basic Paxos 。</li>
</ul>
<p>Raft 算法、ZAB 协议、 Fast Paxos 算法都是基于 Paxos 算法改进而来。</p>
<h4 id="Basic-Paxos-算法"><a href="#Basic-Paxos-算法" class="headerlink" title="Basic Paxos 算法"></a>Basic Paxos 算法</h4><p>Basic Paxos 中存在 3 个重要的角色：</p>
<ol>
<li><strong>提议者（Proposer）</strong>：也可以叫做协调者（coordinator），提议者负责接受客户端的请求并发起提案。提案信息通常包括提案编号 (Proposal ID) 和提议的值 (Value)。</li>
<li><strong>接受者（Acceptor）</strong>：也可以叫做投票员（voter），负责对提议者的提案进行投票，同时需要记住自己的投票历史；</li>
<li><strong>学习者（Learner）</strong>：如果有超过半数接受者就某个提议达成了共识，那么学习者就需要接受这个提议，并就该提议作出运算，然后将运算结果返回给客户端。</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/up-890fa3212e8bf72886a595a34654918486c.png" alt="img"></p>
<p>为了减少实现该算法所需的节点数，一个节点可以身兼多个角色。并且，一个提案被选定需要被半数以上的 Acceptor 接受。这样的话，Basic Paxos 算法还具备容错性，在少于一半的节点出现故障时，集群仍能正常工作。</p>
<h4 id="Multi-Paxos-思想"><a href="#Multi-Paxos-思想" class="headerlink" title="Multi Paxos 思想"></a>Multi Paxos 思想</h4><p>Basic Paxos 算法的仅能就单个值达成共识，为了能够对一系列的值达成共识，我们需要用到 Multi Paxos 思想。</p>
<blockquote>
<p>⚠️<strong>注意</strong> ： Multi-Paxos 只是一种思想，这种思想的核心就是通过多个 Basic Paxos 实例就一系列值达成共识。也就是说，Basic Paxos 是 Multi-Paxos 思想的核心，Multi-Paxos 就是多执行几次 Basic Paxos。</p>
</blockquote>
<p>Multi-Paxos 思想缺少代码实现的必要细节(比如怎么选举领导者)，所以在理解和实现上比较困难。</p>
<p>像 Raft 算法就是 Multi-Paxos 的一个变种，其简化了 Multi-Paxos 的思想，变得更容易被理解以及工程实现，实际项目中可以优先考虑 Raft 算法。</p>
<h3 id="4、Raft-算法"><a href="#4、Raft-算法" class="headerlink" title="4、Raft 算法"></a>4、Raft 算法</h3><h4 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h4><p>数据中心和应用程序在高度动态的环境中运行，为了应对高度动态的环境，它们通过额外的服务器进行横向扩展，并且根据需求进行扩展和收缩。同时，服务器和网络故障也很常见。</p>
<p>因此，系统必须在正常操作期间处理服务器的上下线。它们必须对变故做出反应并在几秒钟内自动适应；对客户来说的话，明显的中断通常是不可接受的。</p>
<p>通过<code>分布式共识</code>来解决这些问题。</p>
<p><strong>拜占庭将军</strong></p>
<blockquote>
<p>假设多位拜占庭将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成是否要进攻的一致性决定？</p>
</blockquote>
<p>解决方案大致可以理解成：先在所有的将军中选出一个大将军，用来做出所有的决定。</p>
<p>举例如下：假如现在一共有 3 个将军 A，B 和 C，每个将军都有一个随机时间的倒计时器，倒计时一结束，这个将军就把自己当成大将军候选人，然后派信使传递选举投票的信息给将军 B 和 C，如果将军 B 和 C 还没有把自己当作候选人（自己的倒计时还没有结束），并且没有把选举票投给其他人，它们就会把票投给将军 A，信使回到将军 A 时，将军 A 知道自己收到了足够的票数，成为大将军。在有了大将军之后，是否需要进攻就由大将军 A 决定，然后再去派信使通知另外两个将军，自己已经成为了大将军。如果一段时间还没收到将军 B 和 C 的回复（信使可能会被暗杀），那就再重派一个信使，直到收到回复。</p>
<p><strong>共识算法</strong></p>
<p>共识是可容错系统中的一个基本问题：即使面对故障，服务器也可以在共享状态上达成一致。</p>
<p>共识算法允许一组节点像一个整体一样一起工作，即使其中的一些节点出现故障也能够继续工作下去，其正确性主要是源于复制状态机的性质：一组<code>Server</code>的状态机计算相同状态的副本，即使有一部分的<code>Server</code>宕机了它们仍然能够继续运行。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/paxos-rsm-architecture.png" alt="rsm-architecture.png"></p>
<p><code>复制状态机架构</code></p>
<p>一般通过使用复制日志来实现复制状态机。每个<code>Server</code>存储着一份包括命令序列的日志文件，状态机会按顺序执行这些命令。因为每个日志包含相同的命令，并且顺序也相同，所以每个状态机处理相同的命令序列。由于状态机是确定性的，所以处理相同的状态，得到相同的输出。</p>
<p>因此共识算法的工作就是保持复制日志的一致性。服务器上的共识模块从客户端接收命令并将它们添加到日志中。它与其他服务器上的共识模块通信，以确保即使某些服务器发生故障。每个日志最终包含相同顺序的请求。一旦命令被正确地复制，它们就被称为已提交。每个服务器的状态机按照日志顺序处理已提交的命令，并将输出返回给客户端，因此，这些服务器形成了一个单一的、高度可靠的状态机。</p>
<p>适用于实际系统的共识算法通常具有以下特性：</p>
<ul>
<li>安全。确保在非拜占庭条件（也就是上文中提到的简易版拜占庭）下的安全性，包括网络延迟、分区、包丢失、复制和重新排序。</li>
<li>高可用。只要大多数服务器都是可操作的，并且可以相互通信，也可以与客户端进行通信，那么这些服务器就可以看作完全功能可用的。因此，一个典型的由五台服务器组成的集群可以容忍任何两台服务器端故障。假设服务器因停止而发生故障；它们稍后可能会从稳定存储上的状态中恢复并重新加入集群。</li>
<li>一致性不依赖时序。错误的时钟和极端的消息延迟，在最坏的情况下也只会造成可用性问题，而不会产生一致性问题。</li>
<li>在集群中大多数服务器响应，命令就可以完成，不会被少数运行缓慢的服务器来影响整体系统性能。</li>
</ul>
<h4 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h4><p><strong>节点类型</strong></p>
<p>一个 Raft 集群包括若干服务器，以典型的 5 服务器集群举例。在任意的时间，每个服务器一定会处于以下三个状态中的一个：</p>
<ul>
<li><code>Leader</code>：负责发起心跳，响应客户端，创建日志，同步日志。</li>
<li><code>Candidate</code>：Leader 选举过程中的临时角色，由 Follower 转化而来，发起投票参与竞选。</li>
<li><code>Follower</code>：接受 Leader 的心跳和日志同步数据，投票给 Candidate。</li>
</ul>
<p>在正常的情况下，只有一个服务器是 Leader，剩下的服务器是 Follower。Follower 是被动的，它们不会发送任何请求，只是响应来自 Leader 和 Candidate 的请求。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/paxos-server-state.png" alt="img"></p>
<p>​                                                   服务器的状态</p>
<p><strong>任期</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/paxos-term.png" alt="img"></p>
<p>raft 算法将时间划分为任意长度的任期（term），任期用连续的数字表示，看作当前 term 号。每一个任期的开始都是一次选举，在选举开始时，一个或多个 Candidate 会尝试成为 Leader。如果一个 Candidate 赢得了选举，它就会在该任期内担任 Leader。如果没有选出 Leader，将会开启另一个任期，并立刻开始下一次选举。raft 算法保证在给定的一个任期最少要有一个 Leader。</p>
<p>每个节点都会存储当前的 term 号，当服务器之间进行通信时会交换当前的 term 号；如果有服务器发现自己的 term 号比其他人小，那么他会更新到较大的 term 值。如果一个 Candidate 或者 Leader 发现自己的 term 过期了，他会立即退回成 Follower。如果一台服务器收到的请求的 term 号是过期的，那么它会拒绝此次请求。</p>
<p><strong>日志</strong></p>
<ul>
<li><code>entry</code>：每一个事件成为 entry，只有 Leader 可以创建 entry。entry 的内容为<code>&lt;term,index,cmd&gt;</code>其中 cmd 是可以应用到状态机的操作。</li>
<li><code>log</code>：由 entry 构成的数组，每一个 entry 都有一个表明自己在 log 中的 index。只有 Leader 才可以改变其他节点的 log。entry 总是先被 Leader 添加到自己的 log 数组中，然后再发起共识请求，获得同意后才会被 Leader 提交给状态机。Follower 只能从 Leader 获取新日志和当前的 commitIndex，然后把对应的 entry 应用到自己的状态机中。</li>
</ul>
<h4 id="领导人选举"><a href="#领导人选举" class="headerlink" title="领导人选举"></a>领导人选举</h4><p>raft 使用心跳机制来触发 Leader 的选举。</p>
<p>如果一台服务器能够收到来自 Leader 或者 Candidate 的有效信息，那么它会一直保持为 Follower 状态，并且刷新自己的 electionElapsed，重新计时。</p>
<p>Leader 会向所有的 Follower 周期性发送心跳来保证自己的 Leader 地位。如果一个 Follower 在一个周期内没有收到心跳信息，就叫做选举超时，然后它就会认为此时没有可用的 Leader，并且开始进行一次选举以选出一个新的 Leader。</p>
<p>为了开始新的选举，Follower 会自增自己的 term 号并且转换状态为 Candidate。然后他会向所有节点发起 RequestVoteRPC 请求， Candidate 的状态会持续到以下情况发生：</p>
<ul>
<li>赢得选举</li>
<li>其他节点赢得选举</li>
<li>一轮选举结束，无人胜出</li>
</ul>
<p>赢得选举的条件是：一个 Candidate 在一个任期内收到了来自集群内的多数选票<code>（N/2+1）</code>，就可以成为 Leader。</p>
<p>在 Candidate 等待选票的时候，它可能收到其他节点声明自己是 Leader 的心跳，此时有两种情况：</p>
<ul>
<li>该 Leader 的 term 号大于等于自己的 term 号，说明对方已经成为 Leader，则自己回退为 Follower。</li>
<li>该 Leader 的 term 号小于自己的 term 号，那么会拒绝该请求并让该节点更新 term。</li>
</ul>
<p>由于可能同一时刻出现多个 Candidate，导致没有 Candidate 获得大多数选票，如果没有其他手段来重新分配选票的话，那么可能会无限重复下去。</p>
<p>raft 使用了随机的选举超时时间来避免上述情况。每一个 Candidate 在发起选举后，都会随机化一个新的枚举超时时间，这种机制使得各个服务器能够分散开来，在大多数情况下只有一个服务器会率先超时；它会在其他服务器超时之前赢得选举。</p>
<h4 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h4><p>一旦选出了 Leader，它就开始接受客户端的请求。每一个客户端的请求都包含一条需要被复制状态机（<code>Replicated State Mechine</code>）执行的命令。</p>
<p>Leader 收到客户端请求后，会生成一个 entry，包含<code>&lt;index,term,cmd&gt;</code>，再将这个 entry 添加到自己的日志末尾后，向所有的节点广播该 entry，要求其他服务器复制这条 entry。</p>
<p>如果 Follower 接受该 entry，则会将 entry 添加到自己的日志后面，同时返回给 Leader 同意。</p>
<p>如果 Leader 收到了多数的成功响应，Leader 会将这个 entry 应用到自己的状态机中，之后可以成为这个 entry 是 committed 的，并且向客户端返回执行结果。</p>
<p>raft 保证以下两个性质：</p>
<ul>
<li>在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们一定有相同的 cmd</li>
<li>在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们前面的 entry 也一定相同</li>
</ul>
<p>通过“仅有 Leader 可以生存 entry”来保证第一个性质，第二个性质需要一致性检查来进行保证。</p>
<p>一般情况下，Leader 和 Follower 的日志保持一致，然后，Leader 的崩溃会导致日志不一样，这样一致性检查会产生失败。Leader 通过强制 Follower 复制自己的日志来处理日志的不一致。这就意味着，在 Follower 上的冲突日志会被领导者的日志覆盖。</p>
<p>为了使得 Follower 的日志和自己的日志一致，Leader 需要找到 Follower 与它日志一致的地方，然后删除 Follower 在该位置之后的日志，接着把这之后的日志发送给 Follower。</p>
<p><code>Leader</code> 给每一个<code>Follower</code> 维护了一个 <code>nextIndex</code>，它表示 <code>Leader</code> 将要发送给该追随者的下一条日志条目的索引。当一个 <code>Leader</code> 开始掌权时，它会将 <code>nextIndex</code> 初始化为它的最新的日志条目索引数+1。如果一个 <code>Follower</code> 的日志和 <code>Leader</code> 的不一致，<code>AppendEntries</code> 一致性检查会在下一次 <code>AppendEntries RPC</code> 时返回失败。在失败之后，<code>Leader</code> 会将 <code>nextIndex</code> 递减然后重试 <code>AppendEntries RPC</code>。最终 <code>nextIndex</code> 会达到一个 <code>Leader</code> 和 <code>Follower</code> 日志一致的地方。这时，<code>AppendEntries</code> 会返回成功，<code>Follower</code> 中冲突的日志条目都被移除了，并且添加所缺少的上了 <code>Leader</code> 的日志条目。一旦 <code>AppendEntries</code> 返回成功，<code>Follower</code> 和 <code>Leader</code> 的日志就一致了，这样的状态会保持到该任期结束。</p>
<h4 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h4><p><strong>选举限制</strong></p>
<p>Leader 需要保证自己存储全部已经提交的日志条目。这样才可以使日志条目只有一个流向：从 Leader 流向 Follower，Leader 永远不会覆盖已经存在的日志条目。</p>
<p>每个 Candidate 发送 RequestVoteRPC 时，都会带上最后一个 entry 的信息。所有节点收到投票信息时，会对该 entry 进行比较，如果发现自己的更新，则拒绝投票给该 Candidate。</p>
<p>判断日志新旧的方式：如果两个日志的 term 不同，term 大的更新；如果 term 相同，更长的 index 更新。</p>
<p><strong>节点崩溃</strong></p>
<p>如果 Leader 崩溃，集群中的节点在 electionTimeout 时间内没有收到 Leader 的心跳信息就会触发新一轮的选主，在选主期间整个集群对外是不可用的。</p>
<p>如果 Follower 和 Candidate 崩溃，处理方式会简单很多。之后发送给它的 RequestVoteRPC 和 AppendEntriesRPC 会失败。由于 raft 的所有请求都是幂等的，所以失败的话会无限的重试。如果崩溃恢复后，就可以收到新的请求，然后选择追加或者拒绝 entry。</p>
<p><strong>时间与可用性</strong></p>
<p>raft 的要求之一就是安全性不依赖于时间：系统不能仅仅因为一些事件发生的比预想的快一些或者慢一些就产生错误。为了保证上述要求，最好能满足以下的时间条件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">broadcastTime &lt;&lt; electionTimeout &lt;&lt; MTBF</span><br></pre></td></tr></table></figure>

<ul>
<li><code>broadcastTime</code>：向其他节点并发发送消息的平均响应时间；</li>
<li><code>electionTimeout</code>：选举超时时间；</li>
<li><code>MTBF(mean time between failures)</code>：单台机器的平均健康时间；</li>
</ul>
<p><code>broadcastTime</code>应该比<code>electionTimeout</code>小一个数量级，为的是使<code>Leader</code>能够持续发送心跳信息（heartbeat）来阻止<code>Follower</code>开始选举；</p>
<p><code>electionTimeout</code>也要比<code>MTBF</code>小几个数量级，为的是使得系统稳定运行。当<code>Leader</code>崩溃时，大约会在整个<code>electionTimeout</code>的时间内不可用；我们希望这种情况仅占全部时间的很小一部分。</p>
<p>由于<code>broadcastTime</code>和<code>MTBF</code>是由系统决定的属性，因此需要决定<code>electionTimeout</code>的时间。</p>
<p>一般来说，broadcastTime 一般为 <code>0.5～20ms</code>，electionTimeout 可以设置为 <code>10～500ms</code>，MTBF 一般为一两个月。</p>
<h3 id="5、Gossip-协议详解"><a href="#5、Gossip-协议详解" class="headerlink" title="5、Gossip 协议详解"></a>5、Gossip 协议详解</h3><h4 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h4><p>在分布式系统中，不同的节点进行数据&#x2F;信息共享是一个基本的需求。</p>
<p>一种比较简单粗暴的方法就是 <strong>集中式发散消息</strong>，简单来说就是一个主节点同时共享最新信息给其他所有节点，比较适合中心化系统。这种方法的缺陷也很明显，节点多的时候不光同步消息的效率低，还太依赖与中心节点，存在单点风险问题。</p>
<p>于是，<strong>分散式发散消息</strong> 的 <strong>Gossip 协议</strong> 就诞生了。</p>
<h4 id="Gossip-协议介绍"><a href="#Gossip-协议介绍" class="headerlink" title="Gossip 协议介绍"></a>Gossip 协议介绍</h4><p><strong>Gossip 协议是一种允许在分布式系统中共享状态的去中心化通信协议，通过这种通信协议，我们可以将信息传播给网络或集群中的所有成员。</strong></p>
<h4 id="Gossip-协议应用"><a href="#Gossip-协议应用" class="headerlink" title="Gossip 协议应用"></a>Gossip 协议应用</h4><p>NoSQL 数据库 Redis 和 Apache Cassandra、服务网格解决方案 Consul 等知名项目都用到了 Gossip 协议，学习 Gossip 协议有助于我们搞清很多技术的底层原理。</p>
<p>我们这里以 Redis Cluster 为例说明 Gossip 协议的实际应用。</p>
<p>我们经常使用的分布式缓存 Redis 的官方集群解决方案（3.0 版本引入） Redis Cluster 就是基于 Gossip 协议来实现集群中各个节点数据的最终一致性。</p>
<p>Redis Cluster 是一个典型的分布式系统，分布式系统中的各个节点需要互相通信。既然要相互通信就要遵循一致的通信协议，Redis Cluster 中的各个节点基于 <strong>Gossip 协议</strong> 来进行通信共享信息，每个 Redis 节点都维护了一份集群的状态信息。</p>
<p>Redis Cluster 的节点之间会相互发送多种 Gossip 消息：</p>
<ul>
<li><strong>MEET</strong> ：在 Redis Cluster 中的某个 Redis 节点上执行 <code>CLUSTER MEET ip port</code> 命令，可以向指定的 Redis 节点发送一条 MEET 信息，用于将其添加进 Redis Cluster 成为新的 Redis 节点。</li>
<li><strong>PING&#x2F;PONG</strong> ：Redis Cluster 中的节点都会定时地向其他节点发送 PING 消息，来交换各个节点状态信息，检查各个节点状态，包括在线状态、疑似下线状态 PFAIL 和已下线状态 FAIL。</li>
<li><strong>FAIL</strong> ：Redis Cluster 中的节点 A 发现 B 节点 PFAIL ，并且在下线报告的有效期限内集群中半数以上的节点将 B 节点标记为 PFAIL，节点 A 就会向集群广播一条 FAIL 消息，通知其他节点将故障节点 B 标记为 FAIL 。</li>
</ul>
<p>下图就是主从架构的 Redis Cluster 的示意图，图中的虚线代表的就是各个节点之间使用 Gossip 进行通信 ，实线表示主从复制。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/redis-cluster-gossip-acd10106-16834631059709.png" alt="img"></p>
<p>有了 Redis Cluster 之后，不需要专门部署 Sentinel 集群服务了。Redis Cluster 相当于是内置了 Sentinel 机制，Redis Cluster 内部的各个 Redis 节点通过 Gossip 协议互相探测健康状态，在故障时可以自动切换。</p>
<h4 id="Gossip-协议消息传播模式"><a href="#Gossip-协议消息传播模式" class="headerlink" title="Gossip 协议消息传播模式"></a>Gossip 协议消息传播模式</h4><p><strong>反熵(Anti-entropy)</strong></p>
<p>反熵就是指消除不同节点中数据的差异，提升节点间数据的相似度，从而降低熵值。</p>
<p>集群中的节点，每隔段时间就随机选择某个其他节点，然后通过互相交换自己的所有数据来消除两者之间的差异，实现数据的最终一致性。</p>
<p>在实现反熵的时候，主要有推、拉和推拉三种方式：</p>
<ul>
<li>推方式，就是将自己的所有副本数据，推给对方，修复对方副本中的熵。</li>
<li>拉方式，就是拉取对方的所有副本数据，修复自己副本中的熵。</li>
<li>推拉就是同时修复自己副本和对方副本中的熵。</li>
</ul>
<p>在我们实际应用场景中，一般不会采用随机的节点进行反熵，而是需要可以的设计一个闭环。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/%E5%8F%8D%E7%86%B5-%E9%97%AD%E7%8E%AF-b8759b45.png" alt="img"></p>
<p>虽然反熵很简单实用，但是，节点过多或者节点动态变化的话，反熵就不太适用了。这个时候，我们想要实现最终一致性就要靠 <strong>谣言传播(Rumor mongering)</strong> 。</p>
<p><strong>谣言传播(Rumor mongering)</strong></p>
<p>谣言传播指的是分布式系统中的一个节点一旦有了新数据之后，就会变为活跃节点，活跃节点会周期性地联系其他节点向其发送新数据，直到所有的节点都存储了该新数据。</p>
<p>谣言传播比较适合节点数量比较多的情况，不过，这种模式下要尽量避免传播的信息包不能太大，避免网络消耗太大。</p>
<p><strong>总结</strong></p>
<ul>
<li>反熵（Anti-Entropy）会传播节点的所有数据，而谣言传播（Rumor-Mongering）只会传播节点新增的数据。</li>
<li>我们一般会给反熵设计一个闭环。</li>
<li>谣言传播（Rumor-Mongering）比较适合节点数量比较多或者节点动态变化的场景。</li>
</ul>
<h4 id="Gossip-协议优势和缺陷"><a href="#Gossip-协议优势和缺陷" class="headerlink" title="Gossip 协议优势和缺陷"></a>Gossip 协议优势和缺陷</h4><p><strong>优势：</strong></p>
<p>1、相比于其他分布式协议&#x2F;算法来说，Gossip 协议理解起来非常简单。</p>
<p>2、能够容忍网络上节点的随意地增加或者减少，宕机或者重启，因为 Gossip 协议下这些节点都是平等的，去中心化的。新增加或者重启的节点在理想情况下最终是一定会和其他节点的状态达到一致。</p>
<p>3、速度相对较快。节点数量比较多的情况下，扩散速度比一个主节点向其他节点传播信息要更快（多播）。</p>
<p><strong>缺陷</strong> :</p>
<p>1、消息需要通过多个传播的轮次才能传播到整个网络中，因此，必然会出现各节点状态不一致的情况。毕竟，Gossip 协议强调的是最终一致，至于达到各个节点的状态一致需要多长时间，谁也无从得知。</p>
<p>2、由于拜占庭将军问题，不允许存在恶意节点。</p>
<p>3、可能会出现消息冗余的问题。由于消息传播的随机性，同一个节点可能会重复收到相同的消息。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>Gossip 协议是一种允许在分布式系统中共享状态的通信协议，通过这种通信协议，我们可以将信息传播给网络或集群中的所有成员。</li>
<li>Gossip 协议被 Redis 、Apache Cassandra、Consul 等项目应用。</li>
<li>谣言传播（Rumor-Mongering）比较适合节点数量比较多或者节点动态变化的场景。</li>
</ul>
<h2 id="二、API-网关"><a href="#二、API-网关" class="headerlink" title="二、API 网关"></a>二、API 网关</h2><h3 id="1、什么是网关？"><a href="#1、什么是网关？" class="headerlink" title="1、什么是网关？"></a>1、什么是网关？</h3><p>微服务背景下，一个系统被拆分为多个服务，但是像安全认证，流量控制，日志，监控等功能是每个服务都需要的，没有网关的话，我们就需要在每个服务中单独实现，这使得我们做了很多重复的事情并且没有一个全局的视图来统一管理这些功能。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/api-gateway-overview.png" alt="网关示意图"></p>
<p>一般情况下，网关可以为我们提供请求转发、安全认证（身份&#x2F;权限认证）、流量控制、负载均衡、降级熔断、日志、监控、参数校验、协议转换等功能。</p>
<p>上面介绍了这么多功能，实际上，网关主要做了两件事情：<strong>请求转发</strong> + <strong>请求过滤</strong>。</p>
<p>由于引入网关之后，会多一步网络转发，因此性能会有一点影响（几乎可以忽略不计，尤其是内网访问的情况下）。 另外，我们需要保障网关服务的高可用，避免单点风险。</p>
<p>如下图所示，网关服务外层通过 Nginx（其他负载均衡设备&#x2F;软件也行） 进⾏负载转发以达到⾼可⽤。Nginx 在部署的时候，尽量也要考虑高可用，避免单点风险。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/server-load-balancing.png" alt="基于 Nginx 的服务端负载均衡"></p>
<h3 id="2、网关能提供哪些功能？"><a href="#2、网关能提供哪些功能？" class="headerlink" title="2、网关能提供哪些功能？"></a>2、网关能提供哪些功能？</h3><p>绝大部分网关可以提供下面这些功能：</p>
<ul>
<li><strong>请求转发</strong> ：将请求转发到目标微服务。</li>
<li><strong>负载均衡</strong> ：根据各个微服务实例的负载情况或者具体的负载均衡策略配置对请求实现动态的负载均衡。</li>
<li><strong>安全认证</strong> ：对用户请求进行身份验证并仅允许可信客户端访问 API，并且还能够使用类似 RBAC 等方式来授权。</li>
<li><strong>参数校验</strong> ：支持参数映射与校验逻辑。</li>
<li><strong>日志记录</strong> ：记录所有请求的行为日志供后续使用。</li>
<li><strong>监控告警</strong> ：从业务指标、机器指标、JVM 指标等方面进行监控并提供配套的告警机制。</li>
<li><strong>流量控制</strong> ：对请求的流量进行控制，也就是限制某一时刻内的请求数。</li>
<li><strong>熔断降级</strong>：实时监控请求的统计信息，达到配置的失败阈值后，自动熔断，返回默认值。</li>
<li><strong>响应缓存</strong>：当用户请求获取的是一些静态的或更新不频繁的数据时，一段时间内多次请求获取到的数据很可能是一样的。对于这种情况可以将响应缓存起来。这样用户请求可以直接在网关层得到响应数据，无需再去访问业务服务，减轻业务服务的负担。</li>
<li><strong>响应聚合</strong>：某些情况下用户请求要获取的响应内容可能会来自于多个业务服务。网关作为业务服务的调用方，可以把多个服务的响应整合起来，再一并返回给用户。</li>
<li><strong>灰度发布</strong> ：将请求动态分流到不同的服务版本（最基本的一种灰度发布）。</li>
<li><strong>异常处理</strong>：对于业务服务返回的异常响应，可以在网关层在返回给用户之前做转换处理。这样可以把一些业务侧返回的异常细节隐藏，转换成用户友好的错误提示返回。</li>
<li><strong>API 文档：</strong> 如果计划将 API 暴露给组织以外的开发人员，那么必须考虑使用 API 文档，例如 Swagger 或 OpenAPI。</li>
<li><strong>协议转换</strong> ：通过协议转换整合后台基于 REST、AMQP、Dubbo 等不同风格和实现技术的微服务，面向 Web Mobile、开放平台等特定客户端提供统一服务。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/up-35e102c633bbe8e0dea1e075ea3fee5dcfb.png" alt="img"></p>
<h3 id="3、常见的网关系统"><a href="#3、常见的网关系统" class="headerlink" title="3、常见的网关系统"></a>3、常见的网关系统</h3><p>SpringCloud Gateway 属于 Spring Cloud 生态系统中的网关，其诞生的目标是为了替代老牌网关 <strong>Zuul</strong>。准确点来说，应该是 Zuul 1.x。SpringCloud Gateway 起步要比 Zuul 2.x 更早。</p>
<p>为了提升网关的性能，SpringCloud Gateway 基于 Spring WebFlux 。Spring WebFlux 使用 Reactor 库来实现响应式编程模型，底层基于 Netty 实现同步非阻塞的 I&#x2F;O。</p>
<p>![img](..&#x2F;images&#x2F;分布式复习提升&#x2F;springcloud-gateway- demo.png)</p>
<p>Spring Cloud Gateway 不仅提供统一的路由方式，并且基于 Filter 链的方式提供了网关基本的功能，例如：安全，监控&#x2F;指标，限流。</p>
<p>Spring Cloud Gateway 和 Zuul 2.x 的差别不大，也是通过过滤器来处理请求。不过，目前更加推荐使用 Spring Cloud Gateway 而非 Zuul，Spring Cloud 生态对其支持更加友好。</p>
<h2 id="三、分布式-ID"><a href="#三、分布式-ID" class="headerlink" title="三、分布式 ID"></a>三、分布式 ID</h2><h3 id="1、分布式-ID-介绍"><a href="#1、分布式-ID-介绍" class="headerlink" title="1、分布式 ID 介绍"></a>1、分布式 ID 介绍</h3><h4 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h4><p><strong>ID 就是数据的唯一标识</strong>。分布式 ID 是分布式系统下的 ID，保证在分布式系统下要做到对数据进行唯一标识。</p>
<h4 id="分布式ID需要满足的需求"><a href="#分布式ID需要满足的需求" class="headerlink" title="分布式ID需要满足的需求"></a>分布式ID需要满足的需求</h4><p>基本的分布式 ID 需要满足下面这些要求：</p>
<ul>
<li><strong>全局唯一</strong>：ID 的全局唯一性肯定是首先要满足的！</li>
<li><strong>高性能</strong>：分布式 ID 的生成速度要快，对本地资源消耗要小。</li>
<li><strong>高可用</strong>：生成分布式 ID 的服务要保证可用性无限接近于 100%。</li>
<li><strong>方便易用</strong>：拿来即用，使用方便，快速接入！</li>
</ul>
<p>除了这些之外，一个比较好的分布式 ID 还应保证：</p>
<ul>
<li><strong>安全</strong>：ID 中不包含敏感信息。</li>
<li><strong>有序递增</strong>：如果要把 ID 存放在数据库的话，ID 的有序性可以提升数据库写入速度。并且，很多时候 ，我们还很有可能会直接通过 ID 来进行排序。</li>
<li><strong>有具体的业务含义</strong>：生成的 ID 如果能有具体的业务含义，可以让定位问题以及开发更透明化（通过 ID 就能确定是哪个业务）。</li>
<li><strong>独立部署</strong>：也就是分布式系统单独有一个发号器服务，专门用来生成分布式 ID。这样就生成 ID 的服务可以和业务相关的服务解耦。不过，这样同样带来了网络调用消耗增加的问题。总的来说，如果需要用到分布式 ID 的场景比较多的话，独立部署的发号器服务还是很有必要的。</li>
</ul>
<h3 id="2、分布式-ID-常见解决方案"><a href="#2、分布式-ID-常见解决方案" class="headerlink" title="2、分布式 ID 常见解决方案"></a>2、分布式 ID 常见解决方案</h3><h4 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h4><h5 id="数据库主键自增"><a href="#数据库主键自增" class="headerlink" title="数据库主键自增"></a>数据库主键自增</h5><p>这种方式就比较简单直白了，就是通过关系型数据库的自增主键产生来唯一的 ID。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/the-primary-key-of-the-database-increases-automatically.png" alt="数据库主键自增"></p>
<p>插入数据使用 <code>replace into</code> 代替 <code>insert into</code>来插入数据，具体步骤是这样的：</p>
<ul>
<li>第一步：尝试把数据插入到表中。</li>
<li>第二步：如果主键或唯一索引字段出现重复数据错误而插入失败时，先从表中删除含有重复关键字值的冲突行，然后再次尝试把数据插入到表中。</li>
</ul>
<p>这种方式的优缺点也比较明显：</p>
<ul>
<li><strong>优点</strong>：实现起来比较简单、ID 有序递增、存储消耗空间小</li>
<li><strong>缺点</strong>：支持的并发量不大、存在数据库单点问题（可以使用数据库集群解决，不过增加了复杂度）、ID 没有具体业务含义、安全问题（比如根据订单 ID 的递增规律就能推算出每天的订单量，商业机密啊！ ）、每次获取 ID 都要访问一次数据库（增加了对数据库的压力，获取速度也慢）</li>
</ul>
<h5 id="数据库号段模式"><a href="#数据库号段模式" class="headerlink" title="数据库号段模式"></a>数据库号段模式</h5><p>数据库的号段模式也是目前比较主流的一种分布式 ID 生成方式。像滴滴开源的 Tinyid 就是基于这种方式来做的。不过，TinyId 使用了双号段缓存、增加多 db 支持等方式来进一步优化。</p>
<p><strong>创建一个数据库表。</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `sequence_id_generator` (</span><br><span class="line">  `id` <span class="type">int</span>(<span class="number">10</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  `current_max_id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;当前最大id&#x27;</span>,</span><br><span class="line">  `step` <span class="type">int</span>(<span class="number">10</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;号段的长度&#x27;</span>,</span><br><span class="line">  `version` <span class="type">int</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;版本号&#x27;</span>,</span><br><span class="line">  `biz_type`    <span class="type">int</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> COMMENT <span class="string">&#x27;业务类型&#x27;</span>,</span><br><span class="line">   <span class="keyword">PRIMARY</span> KEY (`id`)</span><br><span class="line">) ENGINE<span class="operator">=</span>InnoDB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8mb4;</span><br></pre></td></tr></table></figure>

<p><code>current_max_id</code> 字段和<code>step</code>字段主要用于获取批量 ID，获取的批量 id 为：<code>current_max_id ~ current_max_id+step</code>。</p>
<p><code>version</code> 字段主要用于解决并发问题（乐观锁）,<code>biz_type</code> 主要用于表示业务类型。</p>
<p>相比于数据库主键自增的方式，<strong>数据库的号段模式对于数据库的访问次数更少，数据库压力更小。</strong></p>
<p>为了避免单点问题，可以使用主从模式来提高可用性。</p>
<p><strong>数据库号段模式的优缺点:</strong></p>
<p><strong>优点</strong>：</p>
<ul>
<li>可以在不同节点之间进行负载均衡，减轻数据库的压力。</li>
<li>ID 有序递增，存储消耗空间小。</li>
</ul>
<p><strong>缺点</strong>：</p>
<ul>
<li>需要维护号段的分配和回收，以防止序列号的浪费。</li>
<li>如果一个节点发生故障，其分配的号段可能无法被其他节点使用。</li>
<li>存在数据库单点问题（可以使用数据库集群解决，不过增加了复杂度）。</li>
<li>ID 没有具体业务含义，安全问题（比如根据订单 ID 的递增规律就能推算出每天的订单量）。</li>
</ul>
<p>No SQL</p>
<p>可以使用 Redis 的 <code>incr</code> 命令即可实现对 id 原子顺序递增。</p>
<p>Redis 可以通过 Cluster 集群来解决高并发和高可用。Redis 还可以通过 <strong>快照（snapshotting，RDB）</strong>、<strong>只追加文件（append-only file, AOF）</strong>来进行持久化。</p>
<p><strong>Redis 方案的优缺点：</strong></p>
<ul>
<li><strong>优点</strong>：性能不错并且生成的 ID 是有序递增的</li>
<li><strong>缺点</strong>：和数据库主键自增方案的缺点类似</li>
</ul>
<p>MongoDB</p>
<p>MongoDB ObjectId 一共需要 12 个字节存储：</p>
<ul>
<li>0~3：时间戳</li>
<li>3~6：代表机器 ID</li>
<li>7~8：机器进程 ID</li>
<li>9~11：自增值</li>
</ul>
<p><strong>MongoDB 方案的优缺点：</strong></p>
<ul>
<li><strong>优点</strong>：性能不错并且生成的 ID 是有序递增的</li>
<li><strong>缺点</strong>：需要解决重复 ID 问题（当机器时间不对的情况下，可能导致会产生重复 ID）、有安全性问题（ID 生成有规律性）</li>
</ul>
<h4 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h4><h5 id="UUID"><a href="#UUID" class="headerlink" title="UUID"></a>UUID</h5><p>UUID 是 Universally Unique Identifier（通用唯一标识符） 的缩写。UUID 包含 32 个 16 进制数字（8-4-4-4-12）。</p>
<p>JDK 就提供了现成的生成 UUID 的方法:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UUID.randomUUID()</span><br></pre></td></tr></table></figure>

<p>5 种不同的 Version(版本)值分别对应的含义:</p>
<p><strong>版本 1</strong> : UUID 是根据时间和节点 ID（通常是 MAC 地址）生成；</p>
<p><strong>版本 2</strong> : UUID 是根据标识符（通常是组或用户 ID）、时间和节点 ID 生成；</p>
<p><strong>版本 3、版本 5</strong> : 版本 5 - 确定性 UUID 通过散列（hashing）名字空间（namespace）标识符和名称生成；</p>
<p><strong>版本 4</strong> : UUID 使用随机性或伪随机性生成</p>
<p>JDK 中通过 <code>UUID</code> 的 <code>randomUUID()</code> 方法生成的 UUID 的版本默认为 4。</p>
<p>最后，我们再简单分析一下 <strong>UUID 的优缺点</strong>:</p>
<ul>
<li><strong>优点</strong>：生成速度比较快、简单易用</li>
<li><strong>缺点</strong>：存储消耗空间大（32 个字符串，128 位）、 不安全（基于 MAC 地址生成 UUID 的算法会造成 MAC 地址泄露)、无序（非自增）、没有具体业务含义、需要解决重复 ID 问题（当机器时间不对的情况下，可能导致会产生重复 ID）</li>
</ul>
<h5 id="Snowflake-雪花算法"><a href="#Snowflake-雪花算法" class="headerlink" title="Snowflake(雪花算法)"></a>Snowflake(雪花算法)</h5><p>Snowflake 是 Twitter 开源的分布式 ID 生成算法。Snowflake 由 64 bit 的二进制数字组成，这 64 bit 的二进制被分成了几部分，每一部分存储的数据都有特定的含义：</p>
<ul>
<li><strong>第 0 位</strong>：符号位（标识正负），始终为 0，没有用，不用管。</li>
<li><strong>第 1~41 位</strong>：一共 41 位，用来表示时间戳，单位是毫秒，可以支撑 2 ^41 毫秒（约 69 年）</li>
<li><strong>第 42~52 位</strong>：一共 10 位，一般来说，前 5 位表示机房 ID，后 5 位表示机器 ID（实际项目中可以根据实际情况调整）。这样就可以区分不同集群&#x2F;机房的节点。</li>
<li><strong>第 53~64 位</strong>：一共 12 位，用来表示序列号。 序列号为自增值，代表单台机器每毫秒能够产生的最大 ID 数(2^12 &#x3D; 4096),也就是说单台机器每毫秒最多可以生成 4096 个 唯一 ID。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/snowflake-distributed-id-schematic-diagram.png" alt="Snowflake 示意图"></p>
<p>Snowflake 算法的优缺点：</p>
<ul>
<li><strong>优点</strong>：生成速度比较快、生成的 ID 有序递增、比较灵活（可以对 Snowflake 算法进行简单的改造比如加入业务 ID）</li>
<li><strong>缺点</strong>：需要解决重复 ID 问题（依赖时间，当机器时间不对的情况下，可能导致会产生重复 ID）。</li>
</ul>
<h4 id="开源框架"><a href="#开源框架" class="headerlink" title="开源框架"></a>开源框架</h4><p>美团的 Leaf</p>
<p>滴滴的 Tinyid</p>
<h2 id="四、分布式锁"><a href="#四、分布式锁" class="headerlink" title="四、分布式锁"></a>四、分布式锁</h2><h3 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h3><p>对于单机多线程来说，在 Java 中，我们通常使用 <code>ReetrantLock</code> 类、<code>synchronized</code> 关键字这类 JDK 自带的 <strong>本地锁</strong> 来控制一个 JVM 进程内的多个线程对本地共享资源的访问。</p>
<p>分布式锁就是在分布式系统中来控制不同 JVM 的线程来获取资源的访问，</p>
<p>分布式锁需要满足：</p>
<ul>
<li><strong>互斥</strong>：任意一个时刻，锁只能被一个线程持有；</li>
<li><strong>高可用</strong>：锁服务是高可用的。并且，即使客户端的释放锁的代码逻辑出现问题，锁最终一定还是会被释放，不会影响其他线程对共享资源的访问。</li>
<li><strong>可重入</strong>：一个节点获取了锁之后，还可以再次获取锁。</li>
</ul>
<p>分布式锁主要通过 Redis 或 Zookeeper 来实现。</p>
<ul>
<li>Redis 性能更高</li>
<li>Zookeeper 更稳定</li>
</ul>
<h3 id="2、基于-Redis-实现分布式锁"><a href="#2、基于-Redis-实现分布式锁" class="headerlink" title="2、基于 Redis 实现分布式锁"></a>2、基于 Redis 实现分布式锁</h3><p>在 Redis 中， <code>SETNX</code> 命令是可以帮助我们实现互斥。<code>SETNX</code> 即 <strong>SET</strong> if <strong>N</strong>ot e<strong>X</strong>ists (对应 Java 中的 <code>setIfAbsent</code> 方法)，如果 key 不存在的话，才会设置 key 的值。如果 key 已经存在， <code>SETNX</code> 不进行操作。</p>
<p>在删除锁的时候，可以直接使用 <code>DEL</code> 进行删除。但是为了防止误删其他的锁，所以要对 key 值对应的 value 来进行判断。一般通过 <code>Lua</code> 脚本来完成。</p>
<p>用 Lua 脚本是为了保证解锁操作的原子性。因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，从而保证了锁释放操作的原子性。</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 释放锁时，先比较锁对应的 value 值是否相等，避免锁的误释放</span><br><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>

<p>为了避免锁无法被释放，一般还会给锁(key)设计一个过期时间。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SET lockKey uniqueValue EX 3 NX</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>lockKey</strong>：加锁的锁名；</li>
<li><strong>uniqueValue</strong>：能够唯一标示锁的随机字符串；</li>
<li><strong>NX</strong>：只有当 lockKey 对应的 key 值不存在的时候才能 SET 成功；</li>
<li><strong>EX</strong>：过期时间设置（秒为单位）EX 3 标示这个锁有一个 3 秒的自动过期时间。与 EX 对应的是 PX（毫秒为单位），这两个都是过期时间设置。</li>
</ul>
<p><strong>如果操作共享资源的时间大于过期时间，就会出现锁提前过期的问题，进而导致分布式锁直接失效。如果锁的超时时间设置过长，又会影响到性能。</strong></p>
<p>所以要进行锁的续期。</p>
<p><code>Redisson</code> 是一个开源的 Java 语言 Redis 客户端，提供了很多开箱即用的功能，不仅仅包括多种分布式锁的实现。并且，Redisson 还支持 Redis 单机、Redis Sentinel、Redis Cluster 等多种部署架构。</p>
<p>Redisson 通过看门狗(<code>Watch Dog</code>)来监控和续期锁，如果操作共享资源的线程还未执行完成的话，Watch Dog 会不断地延长锁的过期时间，进而保证锁不会因为超时而被释放。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/distributed-lock-redisson-renew-expiration.png" alt="Redisson 看门狗自动续期"></p>
<p>看门狗名字的由来于 <code>getLockWatchdogTimeout()</code> 方法，这个方法返回的是看门狗给锁续期的过期时间，默认为 30 秒。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//默认 30秒，支持修改</span></span><br><span class="line"><span class="keyword">private</span> <span class="type">long</span> <span class="variable">lockWatchdogTimeout</span> <span class="operator">=</span> <span class="number">30</span> * <span class="number">1000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> Config <span class="title function_">setLockWatchdogTimeout</span><span class="params">(<span class="type">long</span> lockWatchdogTimeout)</span> &#123;</span><br><span class="line">    <span class="built_in">this</span>.lockWatchdogTimeout = lockWatchdogTimeout;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getLockWatchdogTimeout</span><span class="params">()</span> &#123;</span><br><span class="line">   <span class="keyword">return</span> lockWatchdogTimeout;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>renewExpiration()</code> 方法包含了看门狗的主要逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">renewExpiration</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//......</span></span><br><span class="line">    <span class="type">Timeout</span> <span class="variable">task</span> <span class="operator">=</span> commandExecutor.getConnectionManager().newTimeout(<span class="keyword">new</span> <span class="title class_">TimerTask</span>() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">(Timeout timeout)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">            <span class="comment">//......</span></span><br><span class="line">            <span class="comment">// 异步续期，基于 Lua 脚本</span></span><br><span class="line">            CompletionStage&lt;Boolean&gt; future = renewExpirationAsync(threadId);</span><br><span class="line">            future.whenComplete((res, e) -&gt; &#123;</span><br><span class="line">                <span class="keyword">if</span> (e != <span class="literal">null</span>) &#123;</span><br><span class="line">                    <span class="comment">// 无法续期</span></span><br><span class="line">                    log.error(<span class="string">&quot;Can&#x27;t update lock &quot;</span> + getRawName() + <span class="string">&quot; expiration&quot;</span>, e);</span><br><span class="line">                    EXPIRATION_RENEWAL_MAP.remove(getEntryName());</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (res) &#123;</span><br><span class="line">                    <span class="comment">// 递归调用实现续期</span></span><br><span class="line">                    renewExpiration();</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// 取消续期</span></span><br><span class="line">                    cancelExpirationRenewal(<span class="literal">null</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 延迟 internalLockLeaseTime/3（默认 10s，也就是 30/3） 再调用</span></span><br><span class="line">    &#125;, internalLockLeaseTime / <span class="number">3</span>, TimeUnit.MILLISECONDS);</span><br><span class="line">    ee.setTimeout(task);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>默认情况下，每过 10 秒，看门狗就会执行续期操作，将锁的超时时间设置为 30 秒。看门狗续期前也会先判断是否需要执行续期操作，需要才会执行续期，否则取消续期操作。</p>
<p>Watch Dog 通过调用 <code>renewExpirationAsync()</code> 方法实现锁的异步续期：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> CompletionStage&lt;Boolean&gt; <span class="title function_">renewExpirationAsync</span><span class="params">(<span class="type">long</span> threadId)</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,</span><br><span class="line">            <span class="comment">// 判断是否为持锁线程，如果是就执行续期操作，就锁的过期时间设置为 30s（默认）</span></span><br><span class="line">            <span class="string">&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot;</span> +</span><br><span class="line">                    <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot;</span> +</span><br><span class="line">                    <span class="string">&quot;return 1; &quot;</span> +</span><br><span class="line">                    <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                    <span class="string">&quot;return 0;&quot;</span>,</span><br><span class="line">            Collections.singletonList(getRawName()),</span><br><span class="line">            internalLockLeaseTime, getLockName(threadId));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看出， <code>renewExpirationAsync</code> 方法其实是调用 Lua 脚本实现的续期，这样做主要是为了保证续期操作的原子性。</p>
<p>我这里以 Redisson 的分布式可重入锁 <code>RLock</code> 为例来说明如何使用 Redisson 实现分布式锁：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1.获取指定的分布式锁对象</span></span><br><span class="line"><span class="type">RLock</span> <span class="variable">lock</span> <span class="operator">=</span> redisson.getLock(<span class="string">&quot;lock&quot;</span>);</span><br><span class="line"><span class="comment">// 2.拿锁且不设置锁超时时间，具备 Watch Dog 自动续期机制</span></span><br><span class="line">lock.lock();</span><br><span class="line"><span class="comment">// 3.执行业务</span></span><br><span class="line">...</span><br><span class="line"><span class="comment">// 4.释放锁</span></span><br><span class="line">lock.unlock();</span><br></pre></td></tr></table></figure>

<p>只有未指定锁超时时间，才会使用到 Watch Dog 自动续期机制。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 手动给锁设置过期时间，不具备 Watch Dog 自动续期机制</span></span><br><span class="line">lock.lock(<span class="number">10</span>, TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure>

<p>Redis 可以通过 Redisson 来实现可重入锁、自旋锁、公平锁等。</p>
<p>Redis 如何解决集群情况下的分布式锁的可靠性？</p>
<p><code>Redlock</code> 算法：客户端向 Redis 集群中的多个独立的 Redis 实例依次请求申请加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。性能太差，如果需要保证可靠可以使用 Zookeeper 实现分布式锁。</p>
<h3 id="3、基于-ZooKeeper-实现分布式锁"><a href="#3、基于-ZooKeeper-实现分布式锁" class="headerlink" title="3、基于 ZooKeeper 实现分布式锁"></a>3、基于 ZooKeeper 实现分布式锁</h3><p>ZooKeeper 分布式锁是基于 <strong>临时顺序节点</strong> 和 <strong>Watcher（事件监听器）</strong> 实现的。</p>
<p>获取锁：</p>
<ol>
<li>首先我们要有一个持久节点 <code>/locks</code>，客户端获取锁就是在 <code>locks</code> 下创建临时顺序节点。</li>
<li>假设客户端 1 创建了 <code>/locks/lock1</code> 节点，创建成功之后，会判断 <code>lock1</code> 是否是 <code>/locks</code> 下最小的子节点。</li>
<li>如果 <code>lock1 </code>是最小的子节点，则获取锁成功。否则，获取锁失败。</li>
<li>如果获取锁失败，则说明有其他的客户端已经成功获取锁。客户端 1 并不会不停地循环去尝试加锁，而是在前一个节点比如 <code>/locks/lock0</code> 上注册一个事件监听器。这个监听器的作用是当前一个节点释放锁之后通知客户端 1（避免无效自旋），这样客户端 1 就加锁成功了。</li>
</ol>
<p>释放锁：</p>
<ol>
<li>成功获取锁的客户端在执行完业务流程之后，会将对应的子节点删除。</li>
<li>成功获取锁的客户端在出现故障之后，对应的子节点由于是临时顺序节点，也会被自动删除，避免了锁无法被释放。</li>
<li>我们前面说的事件监听器其实监听的就是这个子节点删除事件，子节点删除就意味着锁被释放。</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://oss.javaguide.cn/github/javaguide/distributed-system/distributed-lock/distributed-lock-zookeeper.png" alt="img"></p>
<p>使用 Curator 来实现 ZooKeeper 分布式锁。相比于 ZooKeeper 自带的客户端 zookeeper 来说，Curator 的封装更加完善，各种 API 都可以比较方便地使用。</p>
<p><code>Curator</code>主要实现了下面四种锁：</p>
<ul>
<li><code>InterProcessMutex</code>：分布式可重入排它锁</li>
<li><code>InterProcessSemaphoreMutex</code>：分布式不可重入排它锁</li>
<li><code>InterProcessReadWriteLock</code>：分布式读写锁</li>
<li><code>InterProcessMultiLock</code>：将多个锁作为单个实体管理的容器，获取锁的时候获取所有锁，释放锁也会释放所有锁资源（忽略释放失败的锁）。</li>
</ul>
<p>Zokeeper 的节点称为 znode，是 Zookeeper 的数据最小单元。</p>
<ul>
<li><strong>持久（PERSISTENT）节点</strong>：一旦创建就一直存在即使 ZooKeeper 集群宕机，直到将其删除。</li>
<li><strong>临时（EPHEMERAL）节点</strong>：临时节点的生命周期是与 <strong>客户端会话（session）</strong> 绑定的，<strong>会话消失则节点消失</strong> 。并且，<strong>临时节点只能做叶子节点</strong> ，不能创建子节点。</li>
<li><strong>持久顺序（PERSISTENT_SEQUENTIAL）节点</strong>：除了具有持久（PERSISTENT）节点的特性之外， 子节点的名称还具有顺序性。比如 <code>/node1/app0000000001</code>、<code>/node1/app0000000002</code> 。</li>
<li><strong>临时顺序（EPHEMERAL_SEQUENTIAL）节点</strong>：除了具备临时（EPHEMERAL）节点的特性之外，子节点的名称还具有顺序性。</li>
</ul>
<p>临时节点相比持久节点，临时节点会话消失则对应的节点消失。如果客户端发生异常导致没来得及释放锁也没关系，会话失效节点自动被删除，不会发生死锁的问题。</p>
<p>使用 Redis 实现分布式锁的时候，我们是通过过期时间来避免锁无法被释放导致死锁问题的，而 ZooKeeper 直接利用临时节点的特性即可。</p>
<p>使用顺序节点之后，只需要监听前一个节点就好了，对性能更友好。不使用顺序节点，则所有获取锁的节点都会对持锁节点加监听器，进行抢占。</p>
<p>监听器的作用: 当前一个节点对应的客户端释放锁之后（也就是前一个节点被删除之后，监听的是删除事件），通知获取锁失败的客户端（唤醒等待的线程，Java 中的 <code>wait/notifyAll</code> ），让它尝试去获取锁，然后就成功获取锁了。</p>
<p>Curator 的 <code>InterProcessMutex</code> 对可重入锁的实现:</p>
<p>调用 <code>InterProcessMutex#acquire</code>方法获取锁的时候，会调用<code>InterProcessMutex#internalLock</code>方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取可重入互斥锁，直到获取成功为止</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">acquire</span><span class="params">()</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">  <span class="keyword">if</span> (!internalLock(-<span class="number">1</span>, <span class="literal">null</span>)) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IOException</span>(<span class="string">&quot;Lost connection while trying to acquire lock: &quot;</span> + basePath);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>internalLock</code> 方法会先获取当前请求锁的线程，然后从 <code>threadData</code>( <code>ConcurrentMap&lt;Thread, LockData&gt;</code> 类型)中获取当前线程对应的 <code>lockData</code> 。 <code>lockData</code> 包含锁的信息和加锁的次数，是实现可重入锁的关键。</p>
<p>第一次获取锁的时候，<code>lockData</code>为 <code>null</code>。获取锁成功之后，会将当前线程和对应的 <code>lockData</code> 放到 <code>threadData</code> 中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">internalLock</span><span class="params">(<span class="type">long</span> time, TimeUnit unit)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">  <span class="comment">// 获取当前请求锁的线程</span></span><br><span class="line">  <span class="type">Thread</span> <span class="variable">currentThread</span> <span class="operator">=</span> Thread.currentThread();</span><br><span class="line">  <span class="comment">// 拿对应的 lockData</span></span><br><span class="line">  <span class="type">LockData</span> <span class="variable">lockData</span> <span class="operator">=</span> threadData.get(currentThread);</span><br><span class="line">  <span class="comment">// 第一次获取锁的话，lockData 为 null</span></span><br><span class="line">  <span class="keyword">if</span> (lockData != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="comment">// 当前线程获取过一次锁之后</span></span><br><span class="line">    <span class="comment">// 因为当前线程的锁存在， lockCount 自增后返回，实现锁重入.</span></span><br><span class="line">    lockData.lockCount.incrementAndGet();</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 尝试获取锁</span></span><br><span class="line">  <span class="type">String</span> <span class="variable">lockPath</span> <span class="operator">=</span> internals.attemptLock(time, unit, getLockNodeBytes());</span><br><span class="line">  <span class="keyword">if</span> (lockPath != <span class="literal">null</span>) &#123;</span><br><span class="line">    <span class="type">LockData</span> <span class="variable">newLockData</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">LockData</span>(currentThread, lockPath);</span><br><span class="line">     <span class="comment">// 获取锁成功之后，将当前线程和对应的 lockData 放到 threadData 中</span></span><br><span class="line">    threadData.put(currentThread, newLockData);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>LockData</code>是 <code>InterProcessMutex</code>中的一个静态内部类。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ConcurrentMap&lt;Thread, LockData&gt; threadData = Maps.newConcurrentMap();</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">LockData</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 当前持有锁的线程</span></span><br><span class="line">    <span class="keyword">final</span> Thread owningThread;</span><br><span class="line">    <span class="comment">// 锁对应的子节点</span></span><br><span class="line">    <span class="keyword">final</span> String lockPath;</span><br><span class="line">    <span class="comment">// 加锁的次数</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">AtomicInteger</span> <span class="variable">lockCount</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AtomicInteger</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">LockData</span><span class="params">(Thread owningThread, String lockPath)</span></span><br><span class="line">    &#123;</span><br><span class="line">      <span class="built_in">this</span>.owningThread = owningThread;</span><br><span class="line">      <span class="built_in">this</span>.lockPath = lockPath;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://www.haungrd.top">Huang RD</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://www.haungrd.top/2023/06/01/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/">http://www.haungrd.top/2023/06/01/%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://www.haungrd.top" target="_blank">Huang Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a><a class="post-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%90%86%E8%AE%BA/">分布式理论</a><a class="post-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8FID/">分布式ID</a><a class="post-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/">分布式锁</a></div><div class="post_share"><div class="social-share" data-image="https://www.huangrd.top/images/agentina/4.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/06/09/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%80%83%E8%AF%95/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/6.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">操作系统考试</div></div></a></div><div class="next-post pull-right"><a href="/2023/05/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/8.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">数据结构复习提升</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/12/15/Zookeeper%E5%AE%89%E8%A3%85/" title="Zookeeper安装"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/6.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-15</div><div class="title">Zookeeper安装</div></div></a></div><div><a href="/2022/12/15/dubbo/" title="dubbo"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-15</div><div class="title">dubbo</div></div></a></div><div><a href="/2022/12/15/dubbo-admin%E5%AE%89%E8%A3%85/" title="dubbo 安装"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-15</div><div class="title">dubbo 安装</div></div></a></div><div><a href="/2023/09/21/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/" title="分布式事务的解决方案"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/7.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-21</div><div class="title">分布式事务的解决方案</div></div></a></div><div><a href="/2023/01/03/%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E02/" title="分布式搜索引擎ElasticSearch2"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/6.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-03</div><div class="title">分布式搜索引擎ElasticSearch2</div></div></a></div><div><a href="/2022/12/28/%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E01/" title="分布式搜索引擎ElasticSearch1"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/2.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-28</div><div class="title">分布式搜索引擎ElasticSearch1</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8F%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87"><span class="toc-text">分布式复习提升</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E7%90%86%E8%AE%BA%E3%80%81%E7%AE%97%E6%B3%95%E3%80%81%E5%8D%8F%E8%AE%AE"><span class="toc-text">一、理论、算法、协议</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81CAP-%E7%90%86%E8%AE%BA"><span class="toc-text">1、CAP 理论</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-text">简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CAP-%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8%E6%A1%88%E4%BE%8B"><span class="toc-text">CAP 实际应用案例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81Base-%E7%90%86%E8%AE%BA"><span class="toc-text">2、Base 理论</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B-1"><span class="toc-text">简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#BASE-%E7%90%86%E8%AE%BA%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-text">BASE 理论的核心思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#BASE-%E7%90%86%E8%AE%BA%E4%B8%89%E8%A6%81%E7%B4%A0"><span class="toc-text">BASE 理论三要素</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81Paxos-%E7%AE%97%E6%B3%95"><span class="toc-text">3、Paxos 算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B-2"><span class="toc-text">简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Basic-Paxos-%E7%AE%97%E6%B3%95"><span class="toc-text">Basic Paxos 算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Multi-Paxos-%E6%80%9D%E6%83%B3"><span class="toc-text">Multi Paxos 思想</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%E3%80%81Raft-%E7%AE%97%E6%B3%95"><span class="toc-text">4、Raft 算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-text">背景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80"><span class="toc-text">基础</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%86%E5%AF%BC%E4%BA%BA%E9%80%89%E4%B8%BE"><span class="toc-text">领导人选举</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6"><span class="toc-text">日志复制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%89%E5%85%A8%E6%80%A7"><span class="toc-text">安全性</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5%E3%80%81Gossip-%E5%8D%8F%E8%AE%AE%E8%AF%A6%E8%A7%A3"><span class="toc-text">5、Gossip 协议详解</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%83%8C%E6%99%AF-1"><span class="toc-text">背景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Gossip-%E5%8D%8F%E8%AE%AE%E4%BB%8B%E7%BB%8D"><span class="toc-text">Gossip 协议介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Gossip-%E5%8D%8F%E8%AE%AE%E5%BA%94%E7%94%A8"><span class="toc-text">Gossip 协议应用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Gossip-%E5%8D%8F%E8%AE%AE%E6%B6%88%E6%81%AF%E4%BC%A0%E6%92%AD%E6%A8%A1%E5%BC%8F"><span class="toc-text">Gossip 协议消息传播模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Gossip-%E5%8D%8F%E8%AE%AE%E4%BC%98%E5%8A%BF%E5%92%8C%E7%BC%BA%E9%99%B7"><span class="toc-text">Gossip 协议优势和缺陷</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81API-%E7%BD%91%E5%85%B3"><span class="toc-text">二、API 网关</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E4%BB%80%E4%B9%88%E6%98%AF%E7%BD%91%E5%85%B3%EF%BC%9F"><span class="toc-text">1、什么是网关？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E7%BD%91%E5%85%B3%E8%83%BD%E6%8F%90%E4%BE%9B%E5%93%AA%E4%BA%9B%E5%8A%9F%E8%83%BD%EF%BC%9F"><span class="toc-text">2、网关能提供哪些功能？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E5%B8%B8%E8%A7%81%E7%9A%84%E7%BD%91%E5%85%B3%E7%B3%BB%E7%BB%9F"><span class="toc-text">3、常见的网关系统</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F-ID"><span class="toc-text">三、分布式 ID</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F-ID-%E4%BB%8B%E7%BB%8D"><span class="toc-text">1、分布式 ID 介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B-3"><span class="toc-text">简介</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E5%B8%83%E5%BC%8FID%E9%9C%80%E8%A6%81%E6%BB%A1%E8%B6%B3%E7%9A%84%E9%9C%80%E6%B1%82"><span class="toc-text">分布式ID需要满足的需求</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F-ID-%E5%B8%B8%E8%A7%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-text">2、分布式 ID 常见解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-text">数据库</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%BB%E9%94%AE%E8%87%AA%E5%A2%9E"><span class="toc-text">数据库主键自增</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%B7%E6%AE%B5%E6%A8%A1%E5%BC%8F"><span class="toc-text">数据库号段模式</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%97%E6%B3%95"><span class="toc-text">算法</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#UUID"><span class="toc-text">UUID</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Snowflake-%E9%9B%AA%E8%8A%B1%E7%AE%97%E6%B3%95"><span class="toc-text">Snowflake(雪花算法)</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6"><span class="toc-text">开源框架</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-text">四、分布式锁</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81%E7%AE%80%E4%BB%8B"><span class="toc-text">1、简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81%E5%9F%BA%E4%BA%8E-Redis-%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-text">2、基于 Redis 实现分布式锁</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81%E5%9F%BA%E4%BA%8E-ZooKeeper-%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-text">3、基于 ZooKeeper 实现分布式锁</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By Huang RD</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="30" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>