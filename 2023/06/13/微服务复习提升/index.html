<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>微服务复习提升 | Huang Blog</title><meta name="author" content="Huang RD"><meta name="copyright" content="Huang RD"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="微服务复习提升微服务1、SpringCloud常见组件有哪些？ SpringCloud包含的组件很多，有很多功能是重复的。其中最常用组件包括：  注册中心组件：Eureka、Nacos等 负载均衡组件：Ribbon 远程调用组件：OpenFeign 网关组件：Zuul、Gateway 服务保护组件：Hystrix、Sentinel 服务配置管理组件：SpringCloudConfig、Nacos">
<meta property="og:type" content="article">
<meta property="og:title" content="微服务复习提升">
<meta property="og:url" content="http://www.haungrd.top/2023/06/13/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/index.html">
<meta property="og:site_name" content="Huang Blog">
<meta property="og:description" content="微服务复习提升微服务1、SpringCloud常见组件有哪些？ SpringCloud包含的组件很多，有很多功能是重复的。其中最常用组件包括：  注册中心组件：Eureka、Nacos等 负载均衡组件：Ribbon 远程调用组件：OpenFeign 网关组件：Zuul、Gateway 服务保护组件：Hystrix、Sentinel 服务配置管理组件：SpringCloudConfig、Nacos">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.huangrd.top/images/agentina/12.jpg">
<meta property="article:published_time" content="2023-06-13T14:12:57.000Z">
<meta property="article:modified_time" content="2023-06-23T14:35:08.328Z">
<meta property="article:author" content="Huang RD">
<meta property="article:tag" content="微服务">
<meta property="article:tag" content="框架">
<meta property="article:tag" content="Spring Cloud">
<meta property="article:tag" content="Nacos">
<meta property="article:tag" content="Seta">
<meta property="article:tag" content="Gateway">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.huangrd.top/images/agentina/12.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://www.haungrd.top/2023/06/13/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '微服务复习提升',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-06-23 22:35:08'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://getwallpapers.com/wallpaper/full/a/1/8/1057222-free-download-cool-nature-backgrounds-1920x1200-windows-10.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">63</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">84</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">19</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://www.huangrd.top/images/agentina/12.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Huang Blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">微服务复习提升</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-06-13T14:12:57.000Z" title="发表于 2023-06-13 22:12:57">2023-06-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-06-23T14:35:08.328Z" title="更新于 2023-06-23 22:35:08">2023-06-23</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/">微服务</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">16.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>52分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="微服务复习提升"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="微服务复习提升"><a href="#微服务复习提升" class="headerlink" title="微服务复习提升"></a>微服务复习提升</h1><h2 id="微服务"><a href="#微服务" class="headerlink" title="微服务"></a>微服务</h2><h3 id="1、SpringCloud常见组件有哪些？"><a href="#1、SpringCloud常见组件有哪些？" class="headerlink" title="1、SpringCloud常见组件有哪些？"></a>1、SpringCloud常见组件有哪些？</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84.jpg" alt="微服务架构"></p>
<p>SpringCloud包含的组件很多，有很多功能是重复的。其中最常用组件包括：</p>
<ul>
<li>注册中心组件：Eureka、Nacos等</li>
<li>负载均衡组件：Ribbon</li>
<li>远程调用组件：OpenFeign</li>
<li>网关组件：Zuul、Gateway</li>
<li>服务保护组件：Hystrix、Sentinel</li>
<li>服务配置管理组件：SpringCloudConfig、Nacos</li>
<li>缓存：Redis</li>
<li>消息队列</li>
</ul>
<h3 id="2、Nacos的服务注册表结构是怎么样的？"><a href="#2、Nacos的服务注册表结构是怎么样的？" class="headerlink" title="2、Nacos的服务注册表结构是怎么样的？"></a>2、Nacos的服务注册表结构是怎么样的？</h3><p>Nacos采用了数据的分级存储模型，最外层是Namespace，用来隔离环境。然后是Group，用来对服务分组。接下来就是服务（Service）了，一个服务包含多个实例，但是可能处于不同机房，因此Service下有多个集群（Cluster），Cluster下是不同的实例（Instance）。</p>
<p>对应到Java代码中，Nacos采用了一个多层的Map来表示。结构为Map&lt;String, Map&lt;String, Service&gt;&gt;，其中最外层Map的key就是namespaceId，值是一个Map。内层Map的key是group拼接serviceName，值是Service对象。Service对象内部又是一个Map，key是集群名称，值是Cluster对象。而Cluster对象内部维护了Instance的集合。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20210925215305446.png" alt="image-20210925215305446"></p>
<h3 id="3、Nacos如何支撑阿里内部数十万服务注册压力？"><a href="#3、Nacos如何支撑阿里内部数十万服务注册压力？" class="headerlink" title="3、Nacos如何支撑阿里内部数十万服务注册压力？"></a>3、Nacos如何支撑阿里内部数十万服务注册压力？</h3><p>Nacos内部接收到注册的请求时，不会立即写数据，而是将服务注册的任务放入一个<code>阻塞队列</code>就立即响应给客户端。然后利用<code>线程池</code>读取阻塞队列中的任务，异步来完成实例更新，从而提高并发写能力。</p>
<h3 id="4、Nacos如何避免并发读写冲突问题？"><a href="#4、Nacos如何避免并发读写冲突问题？" class="headerlink" title="4、Nacos如何避免并发读写冲突问题？"></a>4、Nacos如何避免并发读写冲突问题？</h3><p>Nacos在更新实例列表时，会采用 <code>CopyOnWrite</code> 技术，首先将旧的实例列表拷贝一份，然后更新拷贝的实例列表，再用更新后的实例列表来覆盖旧的实例列表。</p>
<p>这样在更新的过程中，就不会对读实例列表的请求产生影响，也不会出现脏读问题了。</p>
<h3 id="5、Nacos-和-Eureka-的区别？"><a href="#5、Nacos-和-Eureka-的区别？" class="headerlink" title="5、Nacos 和 Eureka 的区别？"></a>5、Nacos 和 Eureka 的区别？</h3><p>Nacos与Eureka有相同点，也有不同之处，可以从以下几点来描述：</p>
<ul>
<li><strong>接口方式</strong>：Nacos与Eureka都对外暴露了Rest风格的API接口，用来实现服务注册、发现等功能</li>
<li><strong>实例类型</strong>：Nacos的实例有永久和临时实例之分；而Eureka只支持临时实例</li>
<li><strong>健康检测</strong>：Nacos对临时实例采用心跳模式检测，对永久实例采用主动请求来检测；Eureka只支持心跳模式</li>
<li><strong>服务发现</strong>：Nacos支持定时拉取和订阅推送两种模式；Eureka只支持定时拉取模式</li>
</ul>
<h3 id="6、Sentinel-的限流和-Gateway-的限流有什么差别？"><a href="#6、Sentinel-的限流和-Gateway-的限流有什么差别？" class="headerlink" title="6、Sentinel 的限流和 Gateway 的限流有什么差别？"></a>6、Sentinel 的限流和 Gateway 的限流有什么差别？</h3><p>限流算法常见的有三种实现：滑动时间窗口、令牌桶算法、漏桶算法。Gateway则采用了基于Redis实现的令牌桶算法。</p>
<p>而Sentinel内部却比较复杂：</p>
<ul>
<li>默认限流模式是基于滑动时间窗口算法</li>
<li>排队等待的限流模式则基于漏桶算法</li>
<li>而热点参数限流则是基于令牌桶算法</li>
</ul>
<h3 id="7、Sentinel的线程隔离与-Hystix-的线程隔离有什么差别"><a href="#7、Sentinel的线程隔离与-Hystix-的线程隔离有什么差别" class="headerlink" title="7、Sentinel的线程隔离与 Hystix 的线程隔离有什么差别?"></a>7、Sentinel的线程隔离与 Hystix 的线程隔离有什么差别?</h3><p>Hystix默认是基于线程池实现的线程隔离，每一个被隔离的业务都要创建一个独立的线程池，线程过多会带来额外的CPU开销，性能一般，但是隔离性更强。</p>
<p>Sentinel是基于信号量（计数器）实现的线程隔离，不用创建线程池，性能较好，但是隔离性一般。</p>
<h3 id="8、服务注册和发现是什么意思？Spring-Cloud-如何实现服务注册发现？"><a href="#8、服务注册和发现是什么意思？Spring-Cloud-如何实现服务注册发现？" class="headerlink" title="8、服务注册和发现是什么意思？Spring Cloud 如何实现服务注册发现？"></a>8、服务注册和发现是什么意思？Spring Cloud 如何实现服务注册发现？</h3><p>我们当时项目采用的 <code>eureka</code> &#x2F; <code>nacos</code> 作为注册中心，这个也是 spring cloud 体系中的一个核心组件。</p>
<ul>
<li><strong>服务注册</strong>：服务提供者需要把自己的信息注册到 <code>eureka</code>，由 <code>eureka</code> 来保存这些信息，比如服务名称、ip、端口等等</li>
<li><strong>服务发现</strong>：消费者向 eureka 拉取服务列表信息，如果服务提供者有集群，则消费者会利用负载均衡算法，选择一个发起调用</li>
<li><strong>服务监控</strong>：服务提供者会每隔 30 秒向 eureka 发送心跳，报告健康状态，如果 eureka 服务 90 秒没接收到心跳，从 eureka 中剔除</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618143747115.png" alt="image-20230618143747115"></p>
<h3 id="9、Nacos-和-Eureka-有什么区别？"><a href="#9、Nacos-和-Eureka-有什么区别？" class="headerlink" title="9、Nacos 和 Eureka 有什么区别？"></a>9、Nacos 和 Eureka 有什么区别？</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618144318315.png" alt="image-20230618144318315"></p>
<p><strong>共同点</strong>（注册中心）</p>
<ul>
<li>都支持服务注册和服务拉取</li>
<li>都支持服务提供者心跳方式做健康检测</li>
</ul>
<p><strong>区别</strong>（注册中心）</p>
<ul>
<li>Nacos 支持服务端<strong>主动检测</strong>提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式</li>
<li>临时实例心跳不正常会被剔除，非临时实例则不会被剔除</li>
<li>Nacos 支持服务列表变更的<strong>消息推送模式</strong>，服务列表更新更及时</li>
<li>Nacos 集群默认采用 <code>AP</code> 方式，当集群中存在非临时实例时，采用 <code>CP</code> 模式；Eureka 采用 <code>AP</code> 方式</li>
<li>Nacos 还支持了<strong>配置中心</strong>，eureka 则只有注册中心，也是选择使用 nacos 的一个重要原因</li>
</ul>
<h3 id="10、项目的负载均衡是如何实现的？"><a href="#10、项目的负载均衡是如何实现的？" class="headerlink" title="10、项目的负载均衡是如何实现的？"></a>10、项目的负载均衡是如何实现的？</h3><p>负载均衡 <code>Ribbon</code>，发起远程调用 <code>feign</code> 就会使用 Ribbon。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618151401296.png" alt="image-20230618151401296"></p>
<p><strong>Ribbon 负载均衡策略有哪些 ?</strong></p>
<ul>
<li><strong>RoundRobinRule</strong>：简单轮询服务列表来选择服务器</li>
<li><strong>WeightedResponseTimeRule</strong>：按照权重来选择服务器，响应时间越长，权重越小</li>
<li><strong>RandomRule</strong>：随机选择一个可用的服务器</li>
<li>BestAvailableRule：忽略那些短路的服务器，并选择并发数较低的服务器</li>
<li>RetryRule：重试机制的选择逻辑</li>
<li>AvailabilityFilteringRule：可用性敏感策略，先过滤非健康的，再选择连接数较小的实例</li>
<li><strong>ZoneAvoidanceRule</strong>：以区域可用的服务器为基础进行服务器的选择。使用Zone对服务器进行分类，这个Zone可以理解为一个机房、一个机架等。而后再对Zone内的多个服务做轮询</li>
</ul>
<p><strong>如果想自定义负载均衡策略如何实现 ?</strong> </p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618151931862.png" alt="image-20230618151931862"></p>
<p>提供了两种方式：<br>1，创建类实现 <code>IRule</code> 接口，可以指定负载均衡策略（全局）<br>2，在客户端的配置文件中，可以配置某一个服务调用的负载均衡策略（局部）</p>
<h3 id="11、什么是服务雪崩，怎么解决这个问题？"><a href="#11、什么是服务雪崩，怎么解决这个问题？" class="headerlink" title="11、什么是服务雪崩，怎么解决这个问题？"></a>11、什么是服务雪崩，怎么解决这个问题？</h3><p><strong>雪崩</strong>：一个服务失败，导致整条链路的服务都失败的情形</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618152305200.png" alt="image-20230618152305200"></p>
<p>应对服务雪崩有两种方式：</p>
<p><strong>熔断降级（解决）</strong></p>
<p>服务降级是服务自我保护的一种方式，或者保护下游服务的一种方式，用于确保服务不会受请求突增影响变得不可用，确保服务不会崩溃</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618154424270.png" alt="image-20230618154424270"></p>
<p>Hystrix 熔断机制，用于监控微服务调用情况， 默认是关闭的，如果需要开启需要在引导类上添加注解：@EnableCircuitBreaker<br>如果检测到 10 秒内请求的失败率超过 50%，就触发熔断机制。之后每隔 5 秒重新尝试请求微服务，如果微服务不能响应，继续走熔断机制。如果微服务可达，则关闭熔断机制，恢复正常请求.</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618154556283.png" alt="image-20230618154556283"></p>
<p><strong>限流（预防）</strong></p>
<h3 id="12、你们的微服务是怎么监控的？"><a href="#12、你们的微服务是怎么监控的？" class="headerlink" title="12、你们的微服务是怎么监控的？"></a>12、你们的微服务是怎么监控的？</h3><p><code>skywalking</code>：一个分布式系统的应用程序性能监控工具（ Application Performance Managment ），提供了完善的链路追踪能力， apache的顶级项目（前华为产品经理吴晟主导开源）</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618154814836.png" alt="image-20230618154814836"></p>
<ol>
<li>skywalking主要可以监控接口、服务、物理实例的一些状态。特别是在压测的时候可以看到众多服务中哪些服务和接口比较慢，我们可以针对性的分析和优化</li>
<li>我们还在skywalking设置了告警规则，特别是在项目上线以后，如果报错，我们分别设置了可以给相关负责人发短信和发邮件，第一时间知道项目的bug情况，第一时间修复</li>
</ol>
<h3 id="13、解释一下-CAP-和-BASE"><a href="#13、解释一下-CAP-和-BASE" class="headerlink" title="13、解释一下 CAP 和 BASE"></a>13、解释一下 CAP 和 BASE</h3><p><strong>CAP</strong></p>
<p>分布式系统有三个指标：</p>
<ul>
<li><p><code>Consistency</code>（一致性）：用户访问分布式系统中的任意节点，得到的数据必须一致</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618172448356.png" alt="image-20230618172448356"></p>
</li>
<li><p><code>Availability</code>（可用性）：用户访问集群中的任意健康节点，必须能得到响应，而不是超时或拒绝</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618172524762.png" alt="image-20230618172524762"></p>
</li>
<li><p><code>Partition tolerance</code> （分区容错性）</p>
<ul>
<li><p><code>Partition</code>（分区）：因为网络故障或其它原因导致分布式系统中的部分节点与其它节点失去连接，形成独立分区。</p>
</li>
<li><p><code>Tolerance</code>（容错）：在集群出现分区时，整个系统也要持续对外提供服务</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618172647038.png" alt="image-20230618172647038"></p>
</li>
</ul>
</li>
</ul>
<p>CAP 定理：分布式系统无法同时满足这三个指标。</p>
<ul>
<li>分布式系统节点之间肯定是需要网络连接的，分区（P）是必然存在的</li>
<li>如果保证访问的<strong>高可用性</strong>（A）,可以持续对外提供服务，但不能保证数据的强一致性–&gt;  <code>AP</code></li>
<li>如果保证访问的数据<strong>强一致性</strong>（C）,就要放弃高可用性   –&gt; <code>CP</code></li>
</ul>
<p><strong>BASE 理论</strong></p>
<p>BASE 理论是对 CAP 的一种解决思路，包含三个思想：</p>
<ul>
<li><code>B</code>asically <code>A</code>vailable （<strong>基本可用</strong>）：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。</li>
<li><code>S</code>oft State（<strong>软状态</strong>）：在一定时间内，允许出现中间状态，比如临时的不一致状态。</li>
<li><code>E</code>ventually Consistent（<strong>最终一致性</strong>）：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618173026895.png" alt="image-20230618173026895"></p>
<p><strong>解决分布式事务的思想模型</strong>：</p>
<ol>
<li><strong>最终一致思想</strong>：各分支事务分别执行并提交，如果有不一致的情况，再想办法恢复数据（AP）</li>
<li><strong>强一致思想</strong>：各分支事务执行完业务不要提交，等待彼此结果。而后统一提交或回滚（CP）</li>
</ol>
<h3 id="14、你们使用那种分布式事务解决方案？"><a href="#14、你们使用那种分布式事务解决方案？" class="headerlink" title="14、你们使用那种分布式事务解决方案？"></a>14、你们使用那种分布式事务解决方案？</h3><p><strong>Seata 架构</strong></p>
<p>Seata事务管理中有三个重要的角色：</p>
<ul>
<li><code>TC</code> (Transaction Coordinator) - <strong>事务协调者</strong>：维护全局和分支事务的状态，协调全局事务提交或回滚。</li>
<li><code>TM </code> (Transaction Manager) - <strong>事务管理器</strong>：定义全局事务的范围、开始全局事务、提交或回滚全局事务。</li>
<li><code>RM </code> (Resource Manager) - <strong>资源管理器</strong>：管理分支事务处理的资源，与 <code>TC</code> 交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618173526008.png" alt="image-20230618173526008"></p>
<p><strong>seata 的 XA 模式</strong></p>
<p><code>RM</code> 一阶段的工作：</p>
<ol>
<li>注册分支事务到 <code>TC</code></li>
<li>执行分支业务 <code>sql</code> 但不提交</li>
<li>报告执行状态到 <code>TC</code></li>
</ol>
<p><code>TC</code> 二阶段的工作：</p>
<ol>
<li><code>TC</code> 检测各分支事务执行状态<ol>
<li>如果都成功，通知所有RM提交事务</li>
<li>如果有失败，通知所有RM回滚事务</li>
</ol>
</li>
</ol>
<p><code>RM</code> 二阶段的工作：</p>
<ol>
<li>接收<code>TC</code>指令，提交或回滚事务</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618173819968.png" alt="image-20230618173819968"></p>
<p><strong>AT 模式原理</strong></p>
<p>AT 模式同样是分阶段提交的事务模型，不过缺弥补了 XA 模型中资源锁定周期过长的缺陷。</p>
<p>阶段一<code>RM</code>的工作：</p>
<ol>
<li>注册分支事务</li>
<li>记录<code>undo-log</code>（数据快照）</li>
<li>执行业务<code>sql</code>并提交</li>
<li>报告事务状态</li>
</ol>
<p>阶段二<strong>提交</strong>时<code>RM</code>的工作：</p>
<ol>
<li>删除<code>undo-log</code>即可</li>
</ol>
<p>阶段二<strong>回滚</strong>时<code>RM</code>的工作：</p>
<ol>
<li>根据<code>undo-log</code>恢复数据到更新前</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618174059109.png" alt="image-20230618174059109"></p>
<p><strong>TCC 模式原理</strong></p>
<ol>
<li><code>T</code>ry：资源的检测和预留； </li>
<li><code>C</code>onfirm：完成资源操作业务；要求 Try 成功 Confirm 一定要能成功。</li>
<li><code>C</code>ancel：预留资源释放，可以理解为try的反向操作。</li>
</ol>
<p><strong>MQ 分布式事务</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618174448322.png" alt="image-20230618174448322"></p>
<p>描述项目中采用的哪种方案（seata | MQ）</p>
<ul>
<li>seata的XA模式，CP，需要互相等待各个分支事务提交，可以保证强一致性，性能差</li>
<li>seata的AT模式，AP，底层使用undo log 实现，性能好</li>
<li>seata的TCC模式，AP，性能较好，不过需要人工编码实现</li>
<li>MQ模式实现分布式事务，在A服务写数据的时候，需要在同一个事务内发送消息到另外一个事务，异步，性能最好</li>
</ul>
<h3 id="15、分布式服务的接口幂等性如何设计？"><a href="#15、分布式服务的接口幂等性如何设计？" class="headerlink" title="15、分布式服务的接口幂等性如何设计？"></a>15、分布式服务的接口幂等性如何设计？</h3><p><strong>幂等</strong>: 多次调用方法或者接口不会改变业务状态，可以<strong>保证重复调用的结果和单次调用的结果一致。</strong></p>
<p>需要幂等场景：</p>
<ul>
<li>用户重复点击(网络波动)</li>
<li>MQ消息重复</li>
<li>应用使用失败或超时重试机制</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618174738811.png" alt="image-20230618174738811"></p>
<p><strong>token+redis</strong></p>
<p>创建商品、提交订单、转账、支付等操作</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230618174856086.png" alt="image-20230618174856086"></p>
<p>如果是新增数据，可以使用数据库的唯一索引</p>
<p>如果是新增或修改数据：</p>
<ul>
<li>分布式锁，性能较低</li>
<li>使用token+redis来实现，性能较好<ul>
<li>第一次请求，生成一个唯一token存入redis，返回给前端</li>
<li>第二次请求，业务处理，携带之前的token，到redis进行验证，如果存在，可以执行业务，删除token；如果不存在，则直接返回，不处理业务</li>
</ul>
</li>
</ul>
<h3 id="16、项目用到了什么分布式调度？"><a href="#16、项目用到了什么分布式调度？" class="headerlink" title="16、项目用到了什么分布式调度？"></a>16、项目用到了什么分布式调度？</h3><p>首先，还是要描述当时是什么场景用了任务调度。</p>
<p><strong>xxl-job 解决的问题</strong></p>
<ul>
<li>解决集群任务的重复执行问题</li>
<li>cron 表达式定义灵活</li>
<li>定时任务失败了，重试和统计</li>
<li>任务量大，分片执行</li>
</ul>
<p><strong>xxl-job 路由策略有哪些？</strong></p>
<ol>
<li>FIRST（第一个）：固定选择第一个机器；</li>
<li>LAST（最后一个）：固定选择最后一个机器；</li>
<li>ROUND（<strong>轮询</strong>）</li>
<li>RANDOM（随机）：随机选择在线的机器；</li>
<li>CONSISTENT_HASH（一致性HASH）：每个任务按照Hash算法固定选择某一台机器，且所有任务均匀散列在不同机器上。</li>
<li>LEAST_FREQUENTLY_USED（最不经常使用）：使用频率最低的机器优先被选举；</li>
<li>LEAST_RECENTLY_USED（最近最久未使用）：最久未使用的机器优先被选举；</li>
<li>FAILOVER（<strong>故障转移</strong>）：按照顺序依次进行心跳检测，第一个心跳检测成功的机器选定为目标执行器并发起调度；</li>
<li>BUSYOVER（忙碌转移）：按照顺序依次进行空闲检测，第一个空闲检测成功的机器选定为目标执行器并发起调度；</li>
<li>SHARDING_BROADCAST(<strong>分片广播</strong>)：广播触发对应集群中所有机器执行一次任务，同时系统自动传递分片参数；可根据分片参数开发分片任务；</li>
</ol>
<p><strong>xxl-job任务执行失败怎么解决？</strong></p>
<ul>
<li>路由策略选择<strong>故障转移</strong>，使用健康的实例来执行任务</li>
<li>设置重试次数</li>
<li>查看日志+邮件告警来通知相关负责人解决</li>
</ul>
<p><strong>如果有大数据量的任务同时都需要执行，怎么解决？</strong></p>
<ul>
<li>让多个实例一块去执行（部署集群），路由策略<strong>分片广播</strong></li>
<li>在任务执行的代码中可以获取分片总数和当前分片，按照取模的方式分摊到各个实例执行</li>
</ul>
<h2 id="MQ-消息队列"><a href="#MQ-消息队列" class="headerlink" title="MQ 消息队列"></a>MQ 消息队列</h2><h3 id="1、MQ-的选型问题"><a href="#1、MQ-的选型问题" class="headerlink" title="1、MQ 的选型问题"></a>1、MQ 的选型问题</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230614090743577.png" alt="image-20230614090743577">kafka是以吞吐量高而闻名，不过其数据稳定性一般，而且无法保证消息有序性。我们公司的日志收集也有使用，业务模块中则使用的RabbitMQ。</p>
<p>阿里巴巴的RocketMQ基于Kafka的原理，弥补了Kafka的缺点，继承了其高吞吐的优势，其客户端目前以Java为主。但是我们担心阿里巴巴开源产品的稳定性，所以就没有使用。</p>
<p>RabbitMQ基于面向并发的语言Erlang开发，吞吐量不如Kafka，但是对我们公司来讲够用了。而且消息可靠性较好，并且消息延迟极低，集群搭建比较方便。支持多种协议，并且有各种语言的客户端，比较灵活。Spring对RabbitMQ的支持也比较好，使用起来比较方便，比较符合我们公司的需求。</p>
<p>综合考虑我们公司的并发需求以及稳定性需求，我们选择了RabbitMQ。</p>
<h3 id="2、RabbitMQ-如何确保消息的不丢失？"><a href="#2、RabbitMQ-如何确保消息的不丢失？" class="headerlink" title="2、RabbitMQ 如何确保消息的不丢失？"></a>2、RabbitMQ 如何确保消息的不丢失？</h3><p>RabbitMQ 针对消息传递过程中可能发生问题的各个地方，给出了针对性的解决方案：</p>
<ul>
<li>生产者发送消息时可能因为网络问题导致消息没有到达交换机：<ul>
<li>RabbitMQ 提供了 <code>publisher confirm</code> 机制<ul>
<li>生产者发送消息后，可以编写 <code>ConfirmCallback</code> 函数</li>
<li>消息成功到达交换机后，RabbitMQ 会调用 <code>ConfirmCallback</code> 通知消息的发送者，返回 <code>ACK</code></li>
<li>消息如果未到达交换机，RabbitMQ 也会调用 <code>ConfirmCallback</code> 通知消息的发送者，返回 <code>NACK</code></li>
<li>消息超时未发送成功也会抛出异常</li>
</ul>
</li>
</ul>
</li>
<li>消息到达交换机后，如果未能到达队列，也会导致消息丢失：<ul>
<li>RabbitMQ 提供了 <code>publisher return</code> 机制<ul>
<li>生产者可以定义 <code>ReturnCallback</code> 函数</li>
<li>消息到达交换机，未到达队列，RabbitMQ 会调用 <code>ReturnCallback</code> 通知发送者，告知失败原因</li>
</ul>
</li>
</ul>
</li>
<li>消息到达队列后，MQ 宕机也可能导致丢失消息：<ul>
<li>RabbitMQ提供了<strong>持久化</strong>功能，集群的<strong>主从备份功能</strong><ul>
<li>消息持久化，RabbitMQ 会将交换机、队列、消息持久化到磁盘，宕机重启可以恢复消息</li>
<li>镜像集群，仲裁队列，都可以提供主从备份功能，主节点宕机，从节点会自动切换为主，数据依然在</li>
</ul>
</li>
</ul>
</li>
<li>消息投递给消费者后，如果消费者处理不当，也可能导致消息丢失<ul>
<li>SpringAMQP 基于 RabbitMQ 提供了消费者确认机制、消费者重试机制，消费者失败处理策略：<ul>
<li>消费者的确认机制：<ul>
<li>消费者处理消息成功，未出现异常时，Spring 返回 <code>ACK</code> 给 RabbitMQ，消息才被移除</li>
<li>消费者处理消息失败，抛出异常，宕机，Spring 返回 <code>NACK</code> 或者不返回结果，消息不被异常</li>
</ul>
</li>
<li>消费者重试机制：<ul>
<li>默认情况下，消费者处理失败时，消息会再次回到 MQ 队列，然后投递给其它消费者。Spring 提供的消费者重试机制，则是在处理失败后不返回 NACK，而是直接在消费者本地重试。多次重试都失败后，则按照消费者失败处理策略来处理消息。避免了消息频繁入队带来的额外压力。</li>
</ul>
</li>
<li>消费者失败策略：<ul>
<li>当消费者多次本地重试失败时，消息默认会丢弃。</li>
<li>Spring 提供了 <code>Republish</code> 策略，在多次重试都失败，耗尽重试次数后，将消息重新投递给指定的异常交换机，并且会携带上异常栈信息，帮助定位问题。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="3、RabbitMQ-如何避免消息堆积？"><a href="#3、RabbitMQ-如何避免消息堆积？" class="headerlink" title="3、RabbitMQ 如何避免消息堆积？"></a>3、RabbitMQ 如何避免消息堆积？</h3><p>消息堆积问题产生的原因往往是因为消息发送的速度超过了消费者消息处理的速度。因此解决方案无外乎以下三点：</p>
<ul>
<li>增加更多消费者，提高消费速度</li>
<li>在消费者内开启线程池加快消息处理速度</li>
<li>增加队列消息存储上限</li>
</ul>
<p>1）提高消费者处理速度</p>
<p>消费者处理速度是由业务代码决定的，所以我们能做的事情包括：</p>
<ul>
<li>尽可能优化业务代码，提高业务性能</li>
<li>接收到消息后，开启线程池，并发处理多个消息</li>
</ul>
<p>优点：成本低，改改代码即可</p>
<p>缺点：开启线程池会带来额外的性能开销，对于高频、低时延的任务不合适。推荐任务执行周期较长的业务。</p>
<p>2）增加更多消费者</p>
<p>一个队列绑定多个消费者，共同争抢任务，自然可以提供消息处理的速度。</p>
<p>优点：能用钱解决的问题都不是问题。实现简单粗暴</p>
<p>缺点：问题是没有钱。成本太高</p>
<p>3）增加队列消息存储上限</p>
<p>在RabbitMQ的1.8版本后，加入了新的队列模式：Lazy Queue,设置属性 <code>x-queue-mode</code> 为 <code>lazy</code></p>
<p>这种队列不会将消息保存在内存中，而是在收到消息后直接写入磁盘中，理论上没有存储上限。可以解决消息堆积问题。</p>
<p>优点：磁盘存储更安全；存储无上限；避免内存存储带来的Page Out问题，性能更稳定；</p>
<p>缺点：磁盘存储受到IO性能的限制，消息时效性不如内存模式，但影响不大。</p>
<p><strong>惰性队列</strong>的特征如下：</p>
<ul>
<li>接收到消息后直接存入磁盘而非内存</li>
<li>消费者要消费消息时才会从磁盘中读取并加载到内存</li>
<li>支持数百万条的消息存储</li>
</ul>
<h3 id="4、RabbitMQ-如何保证消息的有序性？"><a href="#4、RabbitMQ-如何保证消息的有序性？" class="headerlink" title="4、RabbitMQ 如何保证消息的有序性？"></a>4、RabbitMQ 如何保证消息的有序性？</h3><p>其实 RabbitMQ 是队列存储，天然具备先进先出的特点，只要消息的发送是有序的，那么理论上接收也是有序的。不过当一个队列绑定了多个消费者时，可能出现消息轮询投递给消费者的情况，而消费者的处理顺序就无法保证了。</p>
<p>因此，要保证消息的有序性，需要做的下面几点：</p>
<ul>
<li>保证消息发送的有序性</li>
<li>保证一组有序的消息都发送到同一个队列</li>
<li>保证一个队列只包含一个消费者</li>
</ul>
<h3 id="5、如何防止-MQ-消息被重复消费？"><a href="#5、如何防止-MQ-消息被重复消费？" class="headerlink" title="5、如何防止 MQ 消息被重复消费？"></a>5、如何防止 MQ 消息被重复消费？</h3><p>消息重复消费的原因多种多样，不可避免。所以只能从消费者端入手，只要能保证消息处理的幂等性就可以确保消息不被重复消费。</p>
<p>而幂等性的保证又有很多方案：</p>
<ul>
<li>给每一条消息都添加一个唯一id，在本地记录消息表及消息状态，处理消息时基于数据库表的id唯一性做判断</li>
<li>同样是记录消息表，利用消息状态字段实现基于乐观锁的判断，保证幂等</li>
<li>基于业务本身的幂等性。比如根据id的删除、查询业务天生幂等；新增、修改等业务可以考虑基于数据库id唯一性、或者乐观锁机制确保幂等。本质与消息表方案类似。</li>
</ul>
<h3 id="6、如何保证-RabbitMQ-的高可用？"><a href="#6、如何保证-RabbitMQ-的高可用？" class="headerlink" title="6、如何保证 RabbitMQ 的高可用？"></a>6、如何保证 RabbitMQ 的高可用？</h3><p>要实现 RabbitMQ 的高可用无外乎下面两点：</p>
<ul>
<li>做好交换机、队列、消息的持久化</li>
<li>搭建 RabbitMQ 的镜像集群，做好主从备份。当然也可以使用仲裁队列代替镜像集群。</li>
</ul>
<h3 id="7、使用-MQ-可以解决那些问题？"><a href="#7、使用-MQ-可以解决那些问题？" class="headerlink" title="7、使用 MQ 可以解决那些问题？"></a>7、使用 MQ 可以解决那些问题？</h3><p>RabbitMQ 能解决的问题很多，例如：</p>
<ul>
<li>解耦合：将几个业务关联的微服务调用修改为基于 MQ 的异步通知，可以解除微服务之间的业务耦合。同时还提高了业务性能。</li>
<li>流量削峰：将突发的业务请求放入 MQ 中，作为缓冲区。后端的业务根据自己的处理能力从 MQ 中获取消息，逐个处理任务。流量曲线变的平滑很多</li>
<li>延迟队列：基于 RabbitMQ 的死信队列或者 <code>DelayExchange</code> 插件，可以实现消息发送后，延迟接收的效果。</li>
</ul>
<h3 id="8、MQ-的集群了解吗？"><a href="#8、MQ-的集群了解吗？" class="headerlink" title="8、MQ 的集群了解吗？"></a>8、MQ 的集群了解吗？</h3><p>MQ 会导致系统可用性降低，所以为了保证 MQ 的可用性就需要搭建集群。</p>
<ul>
<li>RabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的</li>
<li>RabbitMQ 有三种模式：<code>单机模式</code>、<code>普通集群模式</code>、<code>镜像集群模式</code></li>
</ul>
<p><strong>单机模式</strong></p>
<p>用于普通的开发和测试。</p>
<p><strong>普通集群（无高可用性）</strong></p>
<p>在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 <code>queue</code>，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 <code>queue</code> 的元数据（元数据可以认为是 <code>queue</code> 的一些配置信息，通过元数据，可以找到 <code>queue</code> 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 <code>queue</code> 所在实例上拉取数据过来。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0MjAyODcz,size_16,color_FFFFFF,t_70.png" alt="在这里插入图片描述"></p>
<p>导致消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。</p>
<p>如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让 RabbitMQ 落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。</p>
<p>普通集群没有什么所谓的高可用性，主要是<code>提高吞吐量</code>的，让集群中多个节点来服务某个 queue 的读写操作。</p>
<p><strong>镜像集群（高可用性）</strong></p>
<p>创建的 <code>queue</code>，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0MjAyODcz,size_16,color_FFFFFF,t_70-16867092772342.png" alt="在这里插入图片描述"></p>
<p><strong>开启镜像集群</strong>：</p>
<p>在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。</p>
<p>任何一个机器宕机了，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。</p>
<p>缺点：</p>
<p>第一，这个性能开销大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！</p>
<p>第二，不是分布式的，就没有扩展性可言了，如果某个 queue 负载很重，加机器，新增的机器也包含了这个 queue 的所有数据，并没有办法线性扩展你的 queue。你想，如果这个 queue 的数据量很大，大到这个机器上的容量无法容纳了，此时该怎么办呢？</p>
<p><strong>如果出现丢数据的情况，怎么办？</strong></p>
<p>可以采用<strong>仲裁队列</strong>，与镜像队列一样，都是主从模式，支持主从数据同步，主从同步基于Raft协议，强一致。<br>并且使用起来也非常简单，不需要额外的配置，在声明队列的时候只要指定这个是仲裁队列即可</p>
<h3 id="9、RabbitMQ中死信交换机-RabbitMQ延迟队列有了解过嘛"><a href="#9、RabbitMQ中死信交换机-RabbitMQ延迟队列有了解过嘛" class="headerlink" title="9、RabbitMQ中死信交换机 ? (RabbitMQ延迟队列有了解过嘛)"></a>9、RabbitMQ中死信交换机 ? (RabbitMQ延迟队列有了解过嘛)</h3><p><strong>延迟队列 &#x3D; 死信交换机 + TTL（生存时间）</strong></p>
<p>当一个队列中的消息满足下列情况之一时，可以成为<code>死信</code>（dead letter）：</p>
<ul>
<li>消费者使用 <code>basic.reject</code> 或 <code>basic.nack</code> 声明消费失败，并且消息的 <code>requeue</code> 参数设置为 <code>false</code></li>
<li>消息是一个过期消息，超时无人消费</li>
<li>要投递的队列消息堆积满了，最早的消息可能成为死信</li>
</ul>
<p>如果该队列配置了 <code>dead-letter-exchange</code> 属性，指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为死信交换机（Dead Letter Exchange，简称DLX）。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230623194522229.png" alt="image-20230623194522229"></p>
<h3 id="10、Kafka-如何保证消息不丢失？"><a href="#10、Kafka-如何保证消息不丢失？" class="headerlink" title="10、Kafka 如何保证消息不丢失？"></a>10、Kafka 如何保证消息不丢失？</h3><p>Kafka 可能出现消息丢失的位置：</p>
<ul>
<li>生产者发送消息到 Brocker 丢失</li>
<li>消息在 Brocker 中存储丢失</li>
<li>消费者从 Brocker 接收消息丢失</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230623195820647.png" alt="image-20230623195820647"></p>
<p><strong>生产者发送消息到Brocker丢失</strong></p>
<ul>
<li>Kafka 可以设置异步发送，来监听发送到 Brocker 的消息是否成功。</li>
<li>如果失败的话，可以记录日志，或者设置自动重试。</li>
</ul>
<p><strong>消息在Brocker中存储丢失</strong></p>
<p>可以使用发送确认机制</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230623200156344.png" alt="image-20230623200156344"></p>
<p><strong>消费者从Brocker接收消息丢失</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230623200246756.png" alt="image-20230623200246756"></p>
<ul>
<li>Kafka 中的分区机制指的是将每个主题划分成多个<strong>分区</strong>（Partition）</li>
<li>topic分区中消息只能由消费者组中的唯一一个消费者处理，不同的分区分配给不同的消费者（同一个消费者组）</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230623222218812.png" alt="image-20230623222218812"></p>
<p><strong>总结</strong>：</p>
<p>需要从三个层面去解决这个问题：</p>
<ul>
<li>生产者发送消息到Brocker丢失<ul>
<li>设置异步发送，发送失败使用回调进行记录或重发</li>
<li>失败重试，参数配置，可以设置重试次数</li>
</ul>
</li>
<li>消息在Brocker中存储丢失<ul>
<li>发送确认acks，选择all，让所有的副本都参与保存数据后确认</li>
</ul>
</li>
<li>消费者从Brocker接收消息丢失<ul>
<li>关闭自动提交偏移量，开启手动提交偏移量</li>
<li>提交方式，最好是同步+异步提交</li>
</ul>
</li>
</ul>
<p>Kafka中消息的重复消费问题如何解决的？</p>
<ul>
<li>关闭自动提交偏移量，开启手动提交偏移量</li>
<li>提交方式，最好是同步+异步提交</li>
<li>幂等方案</li>
</ul>
<h3 id="11、Kafka是如何保证消费的顺序性"><a href="#11、Kafka是如何保证消费的顺序性" class="headerlink" title="11、Kafka是如何保证消费的顺序性"></a>11、Kafka是如何保证消费的顺序性</h3><p>一个 <code>topic</code> 的数据可能存储在不同的分区中，每个分区都有一个按照顺序的存储的偏移量，如果消费者关联了多个分区不能保证顺序性:</p>
<ul>
<li>发送消息时指定分区号</li>
<li>发送消息时按照相同的业务设置相同的key</li>
</ul>
<h3 id="12、Kafka的高可用机制有了解过嘛"><a href="#12、Kafka的高可用机制有了解过嘛" class="headerlink" title="12、Kafka的高可用机制有了解过嘛"></a>12、Kafka的高可用机制有了解过嘛</h3><p>可以从两个层面回答，第一个是<strong>集群</strong>，第二个是<strong>复制机制</strong><br><strong>集群</strong>：<br>一个 kafka 集群由多个 <code>broker</code> 实例组成，即使某一台宕机，也不耽误其他 broker 继续对外提供服务<br><strong>复制机制</strong>：<br>一个 <code>topic</code> 有多个分区，每个分区有多个副本，有一个 <code>leader</code>，其余的是 <code>follower</code>，副本存储在不同的broker 中<br>所有的分区副本的内容是都是相同的，如果 leader 发生故障时，会自动将其中一个 follower 提升为 leader，保证了系统的容错性、高可用性</p>
<p><strong>解释一下复制机制中的 ISR</strong></p>
<p>ISR（in-sync replica）需要同步复制保存的 follower<br>分区副本分为了两类，一个是 ISR，与 leader 副本<strong>同步</strong>保存数据，另外一个普通的副本，是<strong>异步</strong>同步数据，当leader挂掉之后，会优先从ISR副本列表中选取一个作为leader</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230623223015635.png" alt="image-20230623223015635"></p>
<h3 id="13、Kafka-数据清理机制了解过嘛"><a href="#13、Kafka-数据清理机制了解过嘛" class="headerlink" title="13、Kafka 数据清理机制了解过嘛"></a>13、Kafka 数据清理机制了解过嘛</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230623223049437.png" alt="image-20230623223049437"></p>
<p><strong>Kafka 存储结构</strong></p>
<ul>
<li>Kafka 中 <code>topic</code> 的数据存储在分区上，分区如果文件过大会分段存储 <code>segment</code></li>
<li>每个分段都在磁盘上以索引(xxxx.index)和日志文件(xxxx.log)的形式存储 </li>
<li>分段的好处是，第一能够减少单个文件内容的大小，查找数据方便，第二方便kafka进行日志清理。</li>
</ul>
<p><strong>日志的清理策略有两个</strong>：</p>
<ul>
<li>根据消息的保留时间，当消息保存的时间超过了指定的时间，就会触发清理，默认是168小时（ 7天）</li>
<li>根据topic存储的数据大小，当topic所占的日志文件大小大于一定的阈值，则开始删除最久的消息。（默认关闭）</li>
</ul>
<h3 id="14、Kafka-中实现高性能的设计有了解过嘛"><a href="#14、Kafka-中实现高性能的设计有了解过嘛" class="headerlink" title="14、Kafka 中实现高性能的设计有了解过嘛"></a>14、Kafka 中实现高性能的设计有了解过嘛</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230623223316864.png" alt="image-20230623223316864"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230623223324843.png" alt="image-20230623223324843"></p>
<ul>
<li>消息分区：不受单台服务器的限制，可以不受限的处理更多的数据</li>
<li>顺序读写：磁盘顺序读写，提升读写效率</li>
<li>页缓存：把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问</li>
<li>零拷贝：减少上下文切换及数据拷贝</li>
<li>消息压缩：减少磁盘IO和网络IO</li>
<li>分批发送：将消息打包批量发送，减少网络开销</li>
</ul>
<h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><h3 id="1、Redis与Memcache的区别？"><a href="#1、Redis与Memcache的区别？" class="headerlink" title="1、Redis与Memcache的区别？"></a>1、Redis与Memcache的区别？</h3><ul>
<li><code>Redis 支持更丰富的数据类型</code>（支持更复杂的应用场景）：Redis 不仅仅支持简单的 k&#x2F;v 类型的数据，同时还提供list，set，zset，hash 等数据结构的存储。memcache 支持简单的数据类型，String。</li>
<li><code>Redis 支持数据的持久化</code>，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而 Memecache 把数据全部存在内存之中。</li>
<li><code>集群模式</code>：memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的.</li>
<li><code>Redis使用单线程</code>：Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis使用单线程的多路 IO 复用模型。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/1574821356723.png" alt="1574821356723"></p>
<h3 id="2、Redis-的单线程问题"><a href="#2、Redis-的单线程问题" class="headerlink" title="2、Redis 的单线程问题"></a>2、Redis 的单线程问题</h3><p>Redis 快的主要原因是：</p>
<ol>
<li>完全基于内存</li>
<li>数据结构简单，对数据操作也简单</li>
<li>使用多路 I&#x2F;O 复用模型，充分利用 CPU 资源</li>
</ol>
<p>单线程优势有下面几点：</p>
<ul>
<li>代码更清晰，处理逻辑更简单</li>
<li>不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为锁而导致的性能消耗</li>
<li>不存在多进程或者多线程导致的 CPU 切换，充分利用 CPU 资源</li>
</ul>
<h3 id="3、Redis-的持久化方案有哪些？"><a href="#3、Redis-的持久化方案有哪些？" class="headerlink" title="3、Redis 的持久化方案有哪些？"></a>3、Redis 的持久化方案有哪些？</h3><p>1）RDB(数据快照) 持久化</p>
<p>RDB 持久化可以使用 save 或 bgsave，为了不阻塞主进程业务，一般都使用 bgsave，流程：</p>
<ul>
<li>Redis 进程会 fork 出一个子进程（与父进程内存数据一致）。</li>
<li>父进程继续处理客户端请求命令</li>
<li>由子进程将内存中的所有数据写入到一个临时的 RDB 文件中。</li>
<li>完成写入操作之后，旧的 RDB 文件会被新的 RDB 文件替换掉。</li>
</ul>
<p>下面是一些和 RDB 持久化相关的配置：</p>
<ul>
<li><code>save 60 10000</code>：如果在 60 秒内有 10000 个 key 发生改变，那就执行 RDB 持久化。</li>
<li><code>stop-writes-on-bgsave-error yes</code>：如果 Redis 执行 RDB 持久化失败（常见于操作系统内存不足），那么 Redis 将不再接受 client 写入数据的请求。</li>
<li><code>rdbcompression yes</code>：当生成 RDB 文件时，同时进行压缩。</li>
<li><code>dbfilename dump.rdb</code>：将 RDB 文件命名为 dump.rdb。</li>
<li><code>dir /var/lib/redis</code>：将 RDB 文件保存在<code>/var/lib/redis</code>目录下。</li>
</ul>
<p>　　当然在实践中，我们通常会将<code>stop-writes-on-bgsave-error</code>设置为<code>false</code>，同时让监控系统在 Redis 执行 RDB 持久化失败时发送告警，以便人工介入解决，而不是粗暴地拒绝 client 的写入请求。</p>
<p>RDB 持久化的优点：</p>
<ul>
<li>RDB 持久化文件小，Redis 数据恢复时速度快</li>
<li>子进程不影响父进程，父进程可以持续处理客户端命令</li>
<li>子进程 fork 时采用 copy-on-write 方式，大多数情况下，没有太多的内存消耗，效率比较好。</li>
</ul>
<p> RDB 持久化的缺点：</p>
<ul>
<li>子进程 fork 时采用 copy-on-write 方式，如果 Redis 此时写操作较多，可能导致额外的内存占用，甚至内存溢出</li>
<li>RDB 文件压缩会减小文件体积，但通过时会对 CPU有  、额外的消耗</li>
<li>如果业务场景很看重数据的持久性 (durability)，那么不应该采用 RDB 持久化。譬如说，如果 Redis 每 5 分钟执行一次 RDB 持久化，要是 Redis 意外奔溃了，那么最多会丢失 5 分钟的数据。</li>
</ul>
<p>2）AOF（日志持久化） 持久化</p>
<p>　　可以使用<code>appendonly yes</code>配置项来开启 AOF 持久化。Redis 执行 AOF 持久化时，会将接收到的写命令追加到 AOF 文件的末尾，因此 Redis 只要对 AOF 文件中的命令进行回放，就可以将数据库还原到原先的状态。<br>　　与 RDB 持久化相比，AOF 持久化的一个明显优势就是，它可以提高数据的持久性 (durability)。因为在 AOF 模式下，Redis 每次接收到 client 的写命令，就会将命令<code>write()</code>到 AOF 文件末尾。<br>　　然而，在 Linux 中，将数据<code>write()</code>到文件后，数据并不会立即刷新到磁盘，而会先暂存在 OS 的文件系统缓冲区。在合适的时机，OS 才会将缓冲区的数据刷新到磁盘（如果需要将文件内容刷新到磁盘，可以调用<code>fsync()</code>或<code>fdatasync()</code>）。<br>　　通过<code>appendfsync</code>配置项，可以控制 Redis 将命令同步到磁盘的频率：</p>
<ul>
<li><code>always</code>：每次 Redis 将命令<code>write()</code>到 AOF 文件时，都会调用<code>fsync()</code>，将命令刷新到磁盘。这可以保证最好的数据持久性，但却会给系统带来极大的开销。</li>
<li><code>no</code>：Redis 只将命令<code>write()</code>到 AOF 文件。这会让 OS 决定何时将命令刷新到磁盘。</li>
<li><code>everysec</code>：除了将命令<code>write()</code>到 AOF 文件，Redis 还会每秒执行一次<code>fsync()</code>。在实践中，推荐使用这种设置，一定程度上可以保证数据持久性，又不会明显降低 Redis 性能。</li>
</ul>
<p>　　然而，AOF 持久化并不是没有缺点的：Redis 会不断将接收到的写命令追加到 AOF 文件中，导致 AOF 文件越来越大。过大的 AOF 文件会消耗磁盘空间，并且导致 Redis 重启时更加缓慢。为了解决这个问题，在适当情况下，Redis 会对 AOF 文件进行重写，去除文件中冗余的命令，以减小 AOF 文件的体积。在重写 AOF 文件期间， Redis 会启动一个子进程，由子进程负责对 AOF 文件进行重写。<br>　　可以通过下面两个配置项，控制 Redis 重写 AOF 文件的频率：</p>
<ul>
<li><code>auto-aof-rewrite-min-size 64mb</code></li>
<li><code>auto-aof-rewrite-percentage 100</code></li>
</ul>
<p>　　上面两个配置的作用：当 AOF 文件的体积大于 64MB，并且 AOF 文件的体积比上一次重写之后的体积大了至少一倍，那么 Redis 就会执行 AOF 重写。</p>
<p>优点：</p>
<ul>
<li>持久化频率高，数据可靠性高</li>
<li>没有额外的内存或CPU消耗</li>
</ul>
<p>缺点：</p>
<ul>
<li>文件体积大</li>
<li>文件大导致服务数据恢复时效率较低</li>
</ul>
<p><strong>面试话术：</strong></p>
<p>Redis 提供了两种数据持久化的方式，一种是 RDB，另一种是 AOF。默认情况下，Redis 使用的是 RDB 持久化。</p>
<p>RDB持久化文件体积较小，但是保存数据的频率一般较低，可靠性差，容易丢失数据。另外RDB写数据时会采用Fork函数拷贝主进程，可能有额外的内存消耗，文件压缩也会有额外的CPU消耗。</p>
<p>ROF持久化可以做到每秒钟持久化一次，可靠性高。但是持久化文件体积较大，导致数据恢复时读取文件时间较长，效率略低</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20230614171744988.png" alt="image-20230614171744988"></p>
<h3 id="3、Redis的集群方式有哪些？"><a href="#3、Redis的集群方式有哪些？" class="headerlink" title="3、Redis的集群方式有哪些？"></a>3、Redis的集群方式有哪些？</h3><p>Redis集群可以分为<code>主从集群</code>和<code>分片集群</code>两类。</p>
<p><code>主从集群</code>一般一主多从，主库用来写数据，从库用来读数据。结合哨兵，可以再主库宕机时从新选主，<strong>目的是保证Redis的高可用</strong>。</p>
<p><code>分片集群</code>是数据分片，我们会让多个 Redis 节点组成集群，并将 16383 个插槽分到不同的节点上。存储数据时利用对key 做 hash 运算，得到插槽值后存储到对应的节点即可。因为存储数据面向的是插槽而非节点本身，因此可以做到集群动态伸缩。<strong>目的是让Redis能存储更多数据。</strong></p>
<p>1）主从集群</p>
<p>主从集群，也是读写分离集群。一般都是一主多从方式。</p>
<p>Redis 的复制（replication）功能允许用户根据一个 Redis 服务器来创建任意多个该服务器的复制品，其中被复制的服务器为主服务器（master），而通过复制创建出来的服务器复制品则为从服务器（slave）。</p>
<p>只要主从服务器之间的网络连接正常，主从服务器两者会具有相同的数据，主服务器就会一直将发生在自己身上的数据更新同步 给从服务器，从而一直保证主从服务器的数据相同。</p>
<ul>
<li>写数据时只能通过主节点完成</li>
<li>读数据可以从任何节点完成</li>
<li>如果配置了<code>哨兵节点</code>，当master宕机时，哨兵会从salve节点选出一个新的主。</li>
</ul>
<p>主从集群分两种：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/1574821993599.png" alt="1574821993599"> <img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/1574822026037.png" alt="1574822026037"> </p>
<p>带有哨兵的集群：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/1574822077190.png" alt="1574822077190"></p>
<p>2）分片集群</p>
<p>主从集群中，每个节点都要保存所有信息，容易形成木桶效应。并且当数据量较大时，单个机器无法满足需求。此时我们就要使用分片集群了。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/1574822184467.png" alt="1574822184467"> </p>
<p>集群特征：</p>
<ul>
<li><p>每个节点都保存不同数据</p>
</li>
<li><p>所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽.</p>
</li>
<li><p>节点的fail是通过集群中超过半数的节点检测失效时才生效.</p>
</li>
<li><p>客户端与redis节点直连,不需要中间proxy层连接集群中任何一个可用节点都可以访问到数据</p>
</li>
<li><p>redis-cluster把所有的物理节点映射到[0-16383]slot（插槽）上，实现动态伸缩</p>
</li>
</ul>
<p>为了保证Redis中每个节点的高可用，我们还可以给每个节点创建replication（slave节点），如图：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/1574822584357.png" alt="1574822584357"></p>
<p>出现故障时，主从可以及时切换：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/1574822602109.png" alt="1574822602109"></p>
<h3 id="4、Redis-的常用数据类型有哪些？"><a href="#4、Redis-的常用数据类型有哪些？" class="headerlink" title="4、Redis 的常用数据类型有哪些？"></a>4、Redis 的常用数据类型有哪些？</h3><p>持多种类型的数据结构，主要区别是 value 存储的数据格式不同：</p>
<ul>
<li><p>string：最基本的数据类型，二进制安全的字符串，最大 512M。</p>
</li>
<li><p>list：按照添加顺序保持顺序的字符串列表。</p>
</li>
<li><p>set：无序的字符串集合，不存在重复的元素。</p>
</li>
<li><p>sorted set：已排序的字符串集合。</p>
</li>
<li><p>hash：key-value 对格式</p>
</li>
</ul>
<h3 id="5、聊一下-Redis-事务机制"><a href="#5、聊一下-Redis-事务机制" class="headerlink" title="5、聊一下 Redis 事务机制"></a>5、聊一下 Redis 事务机制</h3><p>Redis 事务功能是通过 MULTI、EXEC、DISCARD 和 WATCH 四个原语实现的。Redis 会将一个事务中的所有命令序列化，然后按顺序执行。但是 Redis 事务不支持回滚操作，命令运行出错后，正确的命令会继续执行。</p>
<ul>
<li><code>MULTI</code>: 用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个<strong>待执行命令队列</strong>中</li>
<li><code>EXEC</code>：按顺序执行命令队列内的所有命令。返回所有命令的返回值。事务执行过程中，Redis不会执行其它事务的命令。</li>
<li><code>DISCARD</code>：清空命令队列，并放弃执行事务， 并且客户端会从事务状态中退出</li>
<li><code>WATCH</code>：Redis的乐观锁机制，利用 compare-and-set（<code>CAS</code>）原理，可以监控一个或多个键，一旦其中有一个键被修改，之后的事务就不会执行</li>
</ul>
<p>使用事务时可能会遇上以下两种错误：</p>
<ul>
<li>执行 EXEC 之前，入队的命令可能会出错。比如说，命令可能会产生语法错误（参数数量错误，参数名错误，等等），或者其他更严重的错误，比如内存不足（如果服务器使用 <code>maxmemory</code> 设置了最大内存限制的话）。<ul>
<li>Redis 2.6.5 开始，服务器会对命令入队失败的情况进行记录，并在客户端调用 EXEC 命令时，拒绝执行并自动放弃这个事务。</li>
</ul>
</li>
<li>命令可能在 EXEC 调用之后失败。举个例子，事务中的命令可能处理了错误类型的键，比如将列表命令用在了字符串键上面，诸如此类。<ul>
<li>即使事务中有某个&#x2F;某些命令在执行时产生了错误， 事务中的其他命令仍然会继续执行，不会回滚。</li>
</ul>
</li>
</ul>
<p>为什么 Redis 不支持回滚（roll back）？</p>
<p>以下是这种做法的优点：</p>
<ul>
<li>Redis 命令只会因为错误的语法而失败（并且这些问题不能在入队时发现），或是命令用在了错误类型的键上面：这也就是说，从实用性的角度来说，失败的命令是由<strong>编程错误</strong>造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。</li>
<li>因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。</li>
</ul>
<p>鉴于没有任何机制能避免程序员自己造成的错误， 并且这类错误通常不会在生产环境中出现， 所以 Redis 选择了更简单、更快速的无回滚方式来处理事务。</p>
<p><strong>面试话术：</strong></p>
<p>Redis 事务其实是把一系列 Redis 命令放入队列，然后批量执行，执行过程中不会有其它事务来打断。不过与关系型数据库的事务不同，Redis 事务不支持回滚操作，事务中某个命令执行失败，其它命令依然会执行。</p>
<p>为了弥补不能回滚的问题，Redis 会在事务入队时就检查命令，如果命令异常则会放弃整个事务。</p>
<p>因此，只要程序员编程是正确的，理论上说 Redis 会正确执行所有事务，无需回滚。</p>
<p><strong>如果事务执行一半的时候Redis宕机怎么办？</strong></p>
<p>Redis 有持久化机制，因为可靠性问题，我们一般使用 AOF 持久化。事务的所有命令也会写入 AOF 文件，但是如果在执行 EXEC 命令之前，Redis 已经宕机，则 AOF 文件中事务不完整。使用 <code>redis-check-aof</code> 程序可以移除 AOF 文件中不完整事务的信息，确保服务器可以顺利启动。</p>
<h3 id="6、Redis-的-Key-过期策略"><a href="#6、Redis-的-Key-过期策略" class="headerlink" title="6、Redis 的 Key 过期策略"></a>6、Redis 的 Key 过期策略</h3><h4 id="为什么需要内存回收？"><a href="#为什么需要内存回收？" class="headerlink" title="为什么需要内存回收？"></a>为什么需要内存回收？</h4><ul>
<li>1、在 Redis 中，set 指令可以指定 key 的过期时间，当过期时间到达以后，key 就失效了；</li>
<li>2、Redis 是基于内存操作的，所有的数据都是保存在内存中，一台机器的内存是有限且很宝贵的。</li>
</ul>
<p>基于以上两点，为了保证 Redis 能继续提供可靠的服务，Redis 需要一种机制清理掉不常用的、无效的、多余的数据，失效后的数据需要及时清理，这就需要内存回收了。</p>
<p>Redis 的内存回收主要分为<code>过期删除策略</code>和<code>内存淘汰策略</code>两部分。</p>
<h4 id="过期删除策略"><a href="#过期删除策略" class="headerlink" title="过期删除策略"></a>过期删除策略</h4><p>删除达到过期时间的 key。</p>
<ul>
<li>1）定时删除</li>
</ul>
<p>对于每一个设置了过期时间的 key 都会创建一个定时器，一旦到达过期时间就立即删除。该策略可以立即清除过期的数据，对内存较友好，但是缺点是占用了大量的 CPU 资源去处理过期的数据，会影响Redis的吞吐量和响应时间。</p>
<ul>
<li>2）惰性删除</li>
</ul>
<p>当访问一个 key 时，才判断该 key 是否过期，过期则删除。该策略能最大限度地节省 CPU 资源，但是对内存却十分不友好。有一种极端的情况是可能出现大量的过期 key 没有被再次访问，因此不会被清除，导致占用了大量的内存。</p>
<blockquote>
<p>在计算机科学中，懒惰删除（英文：lazy deletion）指的是从一个散列表（也称哈希表）中删除元素的一种方法。在这个方法中，删除仅仅是指标记一个元素被删除，而不是整个清除它。被删除的位点在插入时被当作空元素，在搜索之时被当作已占据。</p>
</blockquote>
<ul>
<li>3）定期删除</li>
</ul>
<p>每隔一段时间，扫描 Redis 中过期 key 字典，并清除部分过期的 key。该策略是前两者的一个折中方案，还可以通过调整定时扫描的时间间隔和每次扫描的限定耗时，在不同情况下使得 CPU 和内存资源达到最优的平衡效果。</p>
<p>在 Redis 中，<code>同时使用了定期删除和惰性删除</code>。不过 Redis 定期删除采用的是随机抽取的方式删除部分 Key，因此不能保证过期 key 100% 的删除。</p>
<p>Redis 结合了定期删除和惰性删除，基本上能很好的处理过期数据的清理，但是实际上还是有点问题的，如果过期 key 较多，定期删除漏掉了一部分，而且也没有及时去查，即没有走惰性删除，那么就会有大量的过期 key 堆积在内存中，导致redis 内存耗尽，当内存耗尽之后，有新的 key 到来会发生什么事呢？是直接抛弃还是其他措施呢？有什么办法可以接受更多的 key？</p>
<h4 id="内存淘汰策略"><a href="#内存淘汰策略" class="headerlink" title="内存淘汰策略"></a>内存淘汰策略</h4><p>Redis 的内存淘汰策略，是指内存达到 maxmemory 极限时，使用某种算法来决定清理掉哪些数据，以保证新数据的存入。</p>
<p>Redis 的内存淘汰机制包括：</p>
<ul>
<li>noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错。</li>
<li>allkeys-lru：当内存不足以容纳新写入数据时，在键空间（<code>server.db[i].dict</code>）中，移除最近最少使用的 key（这个是最常用的）。</li>
<li>allkeys-random：当内存不足以容纳新写入数据时，在键空间（<code>server.db[i].dict</code>）中，随机移除某个 key。</li>
<li>volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（<code>server.db[i].expires</code>）中，移除最近最少使用的 key。</li>
<li>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（<code>server.db[i].expires</code>）中，随机移除某个 key。</li>
<li>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间（<code>server.db[i].expires</code>）中，有更早过期时间的 key 优先移除。</li>
</ul>
<blockquote>
<p>在配置文件中，通过 maxmemory-policy 可以配置要使用哪一个淘汰机制。</p>
</blockquote>
<p>什么时候会进行淘汰？</p>
<p>Redis 会在每一次处理命令的时候（processCommand 函数调用 freeMemoryIfNeeded）判断当前 redis 是否达到了内存的最大限制，如果达到限制，则使用对应的算法去处理需要删除的key。</p>
<p>在淘汰 key 时，Redis 默认最常用的是 LRU 算法（Latest Recently Used）。Redis 通过在每一个 redisObject 保存 lru 属性来保存 key 最近的访问时间，在实现 LRU 算法时直接读取 key 的 lru 属性。</p>
<p>具体实现时，Redis 遍历每一个 db，从每一个 db 中随机抽取一批样本 key，默认是 3 个 key，再从这 3 个 key中，删除最近最少使用的 key。</p>
<h4 id="面试话术："><a href="#面试话术：" class="headerlink" title="面试话术："></a>面试话术：</h4><p>Redis 过期策略包含<code>定期删除</code>和<code>惰性删除</code>两部分。定期删除是在 Redis 内部有一个定时任务，会定期删除一些过期的key。惰性删除是当用户查询某个 Key 时，会检查这个 Key 是否已经过期，如果没过期则返回用户，如果过期则删除。</p>
<p>但是这两个策略都无法保证过期 key 一定删除，漏网之鱼越来越多，还可能导致内存溢出。当发生内存不足问题时，Redis还会做内存回收。内存回收采用 LRU 策略，就是最近最少使用。其原理就是记录每个 Key 的最近使用时间，内存回收时，随机抽取一些 Key，比较其使用时间，把最老的几个删除。</p>
<p>Redis 的逻辑是：最近使用过的，很可能再次被使用。</p>
<h3 id="7、Redis在项目中的哪些地方有用到"><a href="#7、Redis在项目中的哪些地方有用到" class="headerlink" title="7、Redis在项目中的哪些地方有用到?"></a>7、Redis在项目中的哪些地方有用到?</h3><p>（1）共享 session</p>
<p>在分布式系统下，服务会部署在不同的 <code>tomcat</code>，因此多个 tomcat 的 <code>session</code> 无法共享，以前存储在 session 中的数据无法实现共享，可以用 redis 代替 session，解决分布式系统间数据共享问题。</p>
<p>（2）数据缓存</p>
<p>Redis 采用内存存储，读写效率较高。我们可以把数据库的访问频率高的热点数据存储到 redis 中，这样用户请求时优先从 redis 中读取，减少数据库压力，提高并发能力。</p>
<p>（3）异步队列</p>
<p>Reids 在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得 Redis 能作为一个很好的消息队列平台来使用。而且 Redis 中还有 pub&#x2F;sub 这样的专用结构，用于 1对N 的消息通信模式。</p>
<p>（4）分布式锁</p>
<p>Redis 中的乐观锁机制，可以帮助我们实现分布式锁的效果，用于解决分布式系统下的多线程安全问题</p>
<h3 id="8、Redis-的缓存击穿、缓存雪崩、缓存穿透"><a href="#8、Redis-的缓存击穿、缓存雪崩、缓存穿透" class="headerlink" title="8、Redis 的缓存击穿、缓存雪崩、缓存穿透"></a>8、Redis 的缓存击穿、缓存雪崩、缓存穿透</h3><h4 id="1）缓存穿透"><a href="#1）缓存穿透" class="headerlink" title="1）缓存穿透"></a>1）缓存穿透</h4><p>参考资料：</p>
<ul>
<li><p>什么是缓存穿透</p>
<ul>
<li>正常情况下，我们去查询数据都是存在。那么请求去查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。这种查询不存在数据的现象我们称为<strong>缓存穿透</strong>。</li>
</ul>
</li>
<li><p>穿透带来的问题</p>
<ul>
<li>试想一下，如果有黑客会对你的系统进行攻击，拿一个不存在的 id 去查询数据，会产生大量的请求到数据库去查询。可能会导致你的数据库由于压力过大而宕掉。</li>
</ul>
</li>
<li><p>解决办法</p>
<ul>
<li><code>缓存空值</code>：之所以会发生穿透，就是因为缓存中没有存储这些空数据的 key。从而导致每次查询都到数据库去了。那么我们就可以为这些 key 对应的值设置为 null 丢到缓存里面去。后面再出现查询这个 key 的请求的时候，直接返回 null 。这样，就不用在到数据库中去走一圈了，但是别忘了设置过期时间。</li>
<li>BloomFilter（<code>布隆过滤</code>）：将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力。在缓存之前在加一层 BloomFilter ，在查询的时候先去 BloomFilter 去查询 key 是否存在，如果不存在就直接返回，存在再走查缓存 -&gt; 查 DB。</li>
</ul>
</li>
</ul>
<p><strong>话术：</strong></p>
<p>缓存穿透有两种解决方案：<strong>其一</strong>是把不存在的 key 设置 null 值到缓存中。<strong>其二</strong>是使用布隆过滤器，在查询缓存前先通过布隆过滤器判断 key 是否存在，存在再去查询缓存。</p>
<p>设置 null 值可能被恶意针对，攻击者使用大量不存在的不重复 key ，那么方案一就会缓存大量不存在 key 数据。此时我们还可以对 Key 规定格式模板，然后对不存在的 key 做<strong>正则规范</strong>匹配，如果完全不符合就不用存 null 值到 redis，而是直接返回错误。</p>
<h4 id="2）缓存击穿"><a href="#2）缓存击穿" class="headerlink" title="2）缓存击穿"></a>2）缓存击穿</h4><p><strong>相关资料</strong>：</p>
<ul>
<li>什么是缓存击穿？</li>
</ul>
<p>key 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题。</p>
<p>当这个 key 在失效的瞬间，redis 查询失败，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。</p>
<ul>
<li>解决方案：<ul>
<li>使用<code>互斥锁</code>(mutex key)：mutex，就是互斥。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去 load db，而是先使用 Redis 的 SETNX 去 set 一个互斥 key，当操作返回成功时，再进行 load db 的操作并回设缓存；否则，就重试整个 get 缓存的方法。SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现互斥的效果。</li>
<li><code>软过期</code>：也就是逻辑过期，不使用redis提供的过期时间，而是业务层在数据中存储过期时间信息。查询时由业务程序判断是否过期，如果数据即将过期时，将缓存的时效延长，程序可以派遣一个线程去数据库中获取最新的数据，其他线程这时看到延长了的过期时间，就会继续使用旧数据，等派遣的线程获取最新数据后再更新缓存。</li>
</ul>
</li>
</ul>
<p>推荐使用互斥锁，因为软过期会有业务逻辑侵入和额外的判断。</p>
<p><strong>面试话术</strong>：</p>
<p>缓存击穿主要担心的是某个 Key 过期，更新缓存时引起对数据库的突发高并发访问。因此我们可以在更新缓存时采用互斥锁控制，只允许一个线程去更新缓存，其它线程等待并重新读取缓存。例如 Redis 的 setnx 命令就能实现互斥效果。</p>
<h4 id="3）缓存雪崩"><a href="#3）缓存雪崩" class="headerlink" title="3）缓存雪崩"></a>3）缓存雪崩</h4><p><strong>相关资料</strong>：</p>
<p>缓存雪崩，是指在某一个时间段，缓存集中过期失效。对这批数据的访问查询，都落到了数据库上，对于数据库而言，就会产生周期性的压力波峰。</p>
<p>解决方案：</p>
<ul>
<li>数据分类分批处理：采取不同分类数据，缓存不同周期</li>
<li>相同分类数据：采用固定时长加随机数方式设置缓存</li>
<li>热点数据缓存时间长一些，冷门数据缓存时间短一些</li>
<li>避免 redis 节点宕机引起雪崩，搭建主从集群，保证高可用</li>
</ul>
<p><strong>面试话术：</strong></p>
<p>解决缓存雪崩问题的关键是让缓存 Key的过期时间分散。因此我们可以把数据按照业务分类，然后设置不同过期时间。相同业务类型的 key，设置固定时长加随机数。尽可能保证每个 Key 的过期时间都不相同。</p>
<p>另外，Redis 宕机也可能导致缓存雪崩，因此我们还要搭建 Redis 主从集群及哨兵监控，保证 Redis 的高可用。</p>
<h3 id="9、缓存冷热数据分离"><a href="#9、缓存冷热数据分离" class="headerlink" title="9、缓存冷热数据分离"></a>9、缓存冷热数据分离</h3><p><strong>背景资料</strong>：</p>
<p>Redis 使用的是内存存储，当需要海量数据存储时，成本非常高。</p>
<p>经过调研发现，当前主流 DDR3 内存和主流 SATA SSD 的单位成本价格差距大概在 20 倍左右，为了优化 redis 机器综合成本，我们考虑实现基于<strong>热度统计 的数据分级存储</strong>及数据在 RAM&#x2F;FLASH 之间的动态交换，从而大幅度降低成本，达到性能与成本的高平衡。</p>
<p>基本思路：基于 key 访问次数(LFU)的热度统计算法识别出热点数据，并将热点数据保留在 redis 中，对于无访问&#x2F;访问次数少的数据则转存到 SSD 上，如果 SSD 上的 key 再次变热，则重新将其加载到 redis 内存中。</p>
<p>目前流行的高性能磁盘存储，并且遵循 Redis 协议的方案包括：</p>
<ul>
<li>SSDB：<a target="_blank" rel="noopener" href="http://ssdb.io/zh_cn/">http://ssdb.io/zh_cn/</a></li>
<li>RocksDB：<a target="_blank" rel="noopener" href="https://rocksdb.org.cn/">https://rocksdb.org.cn/</a></li>
</ul>
<p>因此，我们就需要在应用程序与缓存服务之间引入代理，实现 Redis 和 SSD 之间的切换，如图：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/image-20200521115702956.png" alt="image-20200521115702956"></p>
<p>这样的代理方案阿里云提供的就有。当然也有一些开源方案，例如：<a target="_blank" rel="noopener" href="https://github.com/JingchengLi/swapdb">https://github.com/JingchengLi/swapdb</a></p>
<h3 id="10、Redis-实现分布式锁"><a href="#10、Redis-实现分布式锁" class="headerlink" title="10、Redis 实现分布式锁"></a>10、Redis 实现分布式锁</h3><p>分布式锁要满足的条件：</p>
<ul>
<li>多进程互斥：同一时刻，只有一个进程可以获取锁</li>
<li>保证锁可以释放：任务结束或出现异常，锁一定要释放，避免死锁</li>
<li>阻塞锁（可选）：获取锁失败时可否重试</li>
<li>重入锁（可选）：获取锁的代码递归调用时，依然可以获取锁</li>
</ul>
<h4 id="1）最基本的分布式锁："><a href="#1）最基本的分布式锁：" class="headerlink" title="1）最基本的分布式锁："></a>1）最基本的分布式锁：</h4><p>利用 Redis 的 <code>setnx</code> 命令，这个命令的特征时如果多次执行，只有第一次执行会成功，可以实现<code>互斥</code>的效果。但是为了保证服务宕机时也可以释放锁，需要利用 <code>expire</code> 命令给锁设置一个有效期</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">setnx lock thread-01 # 尝试获取锁</span><br><span class="line">expire lock 10 # 设置有效期</span><br></pre></td></tr></table></figure>

<p><strong>面试官问题1</strong>：如果 expire 之前服务宕机怎么办？</p>
<p>要保证 setnx 和 expire 命令的原子性。redis 的 set 命令可以满足：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set key value [NX] [EX time] </span><br></pre></td></tr></table></figure>

<p>需要添加 nx 和 ex 的选项：</p>
<ul>
<li><code>NX</code>：与 setnx 一致，第一次执行成功</li>
<li><code>EX</code>：设置过期时间</li>
</ul>
<p><strong>面试官问题2</strong>：释放锁的时候，如果自己的锁已经过期了，此时会出现安全漏洞，如何解决？</p>
<p>在锁中存储当前进程和线程标识，释放锁时对锁的标识判断，如果是自己的则删除，不是则放弃操作。</p>
<p>但是这两步操作要保证原子性，需要通过Lua脚本来实现。</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> redis.call(<span class="string">&quot;get&quot;</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>]) <span class="keyword">then</span></span><br><span class="line">    redis.call(<span class="string">&quot;del&quot;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>



<h4 id="2）可重入分布式锁"><a href="#2）可重入分布式锁" class="headerlink" title="2）可重入分布式锁"></a>2）可重入分布式锁</h4><p>如果有重入的需求，则除了在锁中记录进程标识，还要记录重试次数，流程如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/../images/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/1574824172228.png" alt="1574824172228"> </p>
<p>下面我们假设锁的 key 为“<code>lock</code>”，hashKey 是当前线程的id：“<code>threadId</code>”，锁自动释放时间假设为20</p>
<p>获取锁的步骤：</p>
<ul>
<li>1、判断lock是否存在 <code>EXISTS lock</code><ul>
<li>存在，说明有人获取锁了，下面判断是不是自己的锁<ul>
<li>判断当前线程id作为hashKey是否存在：<code>HEXISTS lock threadId</code><ul>
<li>不存在，说明锁已经有了，且不是自己获取的，锁获取失败，end</li>
<li>存在，说明是自己获取的锁，重入次数+1：<code>HINCRBY lock threadId 1</code>，去到步骤3</li>
</ul>
</li>
</ul>
</li>
<li>2、不存在，说明可以获取锁，<code>HSET key threadId 1</code></li>
<li>3、设置锁自动释放时间，<code>EXPIRE lock 20</code></li>
</ul>
</li>
</ul>
<p>释放锁的步骤：</p>
<ul>
<li>1、判断当前线程id作为hashKey是否存在：<code>HEXISTS lock threadId</code><ul>
<li>不存在，说明锁已经失效，不用管了</li>
<li>存在，说明锁还在，重入次数减1：<code>HINCRBY lock threadId -1</code>，获取新的重入次数</li>
</ul>
</li>
<li>2、判断重入次数是否为0：<ul>
<li>为0，说明锁全部释放，删除key：<code>DEL lock</code></li>
<li>大于0，说明锁还在使用，重置有效时间：<code>EXPIRE lock 20</code></li>
</ul>
</li>
</ul>
<p>对应的Lua脚本如下：</p>
<p>首先是获取锁：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">local</span> key = KEYS[<span class="number">1</span>]; <span class="comment">-- 锁的key</span></span><br><span class="line"><span class="keyword">local</span> threadId = ARGV[<span class="number">1</span>]; <span class="comment">-- 线程唯一标识</span></span><br><span class="line"><span class="keyword">local</span> releaseTime = ARGV[<span class="number">2</span>]; <span class="comment">-- 锁的自动释放时间</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(redis.call(<span class="string">&#x27;exists&#x27;</span>, key) == <span class="number">0</span>) <span class="keyword">then</span> <span class="comment">-- 判断是否存在</span></span><br><span class="line">	redis.call(<span class="string">&#x27;hset&#x27;</span>, key, threadId, <span class="string">&#x27;1&#x27;</span>); <span class="comment">-- 不存在, 获取锁</span></span><br><span class="line">	redis.call(<span class="string">&#x27;expire&#x27;</span>, key, releaseTime); <span class="comment">-- 设置有效期</span></span><br><span class="line">	<span class="keyword">return</span> <span class="number">1</span>; <span class="comment">-- 返回结果</span></span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(redis.call(<span class="string">&#x27;hexists&#x27;</span>, key, threadId) == <span class="number">1</span>) <span class="keyword">then</span> <span class="comment">-- 锁已经存在，判断threadId是否是自己	</span></span><br><span class="line">	redis.call(<span class="string">&#x27;hincrby&#x27;</span>, key, threadId, <span class="string">&#x27;1&#x27;</span>); <span class="comment">-- 不存在, 获取锁，重入次数+1</span></span><br><span class="line">	redis.call(<span class="string">&#x27;expire&#x27;</span>, key, releaseTime); <span class="comment">-- 设置有效期</span></span><br><span class="line">	<span class="keyword">return</span> <span class="number">1</span>; <span class="comment">-- 返回结果</span></span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>; <span class="comment">-- 代码走到这里,说明获取锁的不是自己，获取锁失败</span></span><br></pre></td></tr></table></figure>

<p>然后是释放锁：</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">local</span> key = KEYS[<span class="number">1</span>]; <span class="comment">-- 锁的key</span></span><br><span class="line"><span class="keyword">local</span> threadId = ARGV[<span class="number">1</span>]; <span class="comment">-- 线程唯一标识</span></span><br><span class="line"><span class="keyword">local</span> releaseTime = ARGV[<span class="number">2</span>]; <span class="comment">-- 锁的自动释放时间</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (redis.call(<span class="string">&#x27;HEXISTS&#x27;</span>, key, threadId) == <span class="number">0</span>) <span class="keyword">then</span> <span class="comment">-- 判断当前锁是否还是被自己持有</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span>; <span class="comment">-- 如果已经不是自己，则直接返回</span></span><br><span class="line"><span class="keyword">end</span>;</span><br><span class="line"><span class="keyword">local</span> count = redis.call(<span class="string">&#x27;HINCRBY&#x27;</span>, key, threadId, <span class="number">-1</span>); <span class="comment">-- 是自己的锁，则重入次数-1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (count &gt; <span class="number">0</span>) <span class="keyword">then</span> <span class="comment">-- 判断是否重入次数是否已经为0</span></span><br><span class="line">    redis.call(<span class="string">&#x27;EXPIRE&#x27;</span>, key, releaseTime); <span class="comment">-- 大于0说明不能释放锁，重置有效期然后返回</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span>;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    redis.call(<span class="string">&#x27;DEL&#x27;</span>, key); <span class="comment">-- 等于0说明可以释放锁，直接删除</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nil</span>;</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure>



<h4 id="3）高可用的锁"><a href="#3）高可用的锁" class="headerlink" title="3）高可用的锁"></a>3）高可用的锁</h4><p><code>面试官问题</code>：redis 分布式锁依赖与 redis ，如果 redis 宕机则锁失效。如何解决？</p>
<p>此时大多数同学会回答说：搭建主从集群，做数据备份。</p>
<p>这样就进入了陷阱，因为面试官的下一个问题就来了：</p>
<p><code>面试官问题</code>：如果搭建主从集群做数据备份时，进程 A 获取锁，master 还没有把数据备份到 slave，master 宕机，slave 升级为 master，此时原来锁失效，其它进程也可以获取锁，出现安全问题。如何解决？</p>
<p>关于这个问题，Redis 官网给出了解决方案，使用 RedLock 思路可以解决：</p>
<blockquote>
<p>在 Redis 的分布式环境中，我们假设有 N 个 Redis master。这些节点完全互相独立， 不存在主从复制或者其他集群协调机制。之前我们已经描述了在 Redis 单实例下怎么安全地获取和释放锁。我们确保将在每（N)个实例上使用此方法获取和释放锁。在这个样例中，我们假设有 5 个 Redis master 节点，这是一个比较合理的设置，所以我们需要在5 台机器上面或者 5 台虚拟机上面运行这些实例，这样保证他们不会同时都宕掉。</p>
<p>为了取到锁，客户端应该执行以下操作:</p>
<ol>
<li>获取当前 Unix 时间，以毫秒为单位。</li>
<li>依次尝试从 N 个实例，使用相同的 key 和随机值获取锁。在步骤2，当向 Redis 设置锁时,客户端应该设置一个网络连接和响应超时时间，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为 10 秒，则超时时间应该在5-50毫秒之间。这样可以避免服务器端Redis已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试另外一个Redis实例。</li>
<li>客户端使用当前时间减去开始获取锁时间（步骤1记录的时间）就得到获取锁使用的时间。当且仅当从大多数（这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。</li>
<li>如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。</li>
<li>如果因为某些原因，获取锁失败（<em>没有</em>在至少N&#x2F;2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在所有的Redis实例上进行解锁（即便某些Redis实例根本就没有加锁成功）。</li>
</ol>
</blockquote>
<h3 id="11、如何实现数据库与缓存数据一致？"><a href="#11、如何实现数据库与缓存数据一致？" class="headerlink" title="11、如何实现数据库与缓存数据一致？"></a>11、如何实现数据库与缓存数据一致？</h3><p>面试话术：</p>
<p>实现方案有下面几种：</p>
<ul>
<li><p>本地缓存同步：当前微服务的数据库数据与缓存数据同步，可以直接在数据库修改时加入对 Redis 的修改逻辑，保证一致。</p>
<ul>
<li>延迟双删</li>
<li>加读写锁来完成双写一致</li>
</ul>
</li>
<li><p>跨服务缓存同步：服务 A 调用了服务 B，并对查询结果缓存。服务 B 数据库修改，可以通过 MQ 通知服务 A，服务 A 修改 Redis 缓存数据</p>
</li>
<li><p>通用方案：使用 Canal 框架，伪装成 MySQL 的salve节点，监听 MySQL 的 binLog 变化，然后修改 Redis  缓存数据</p>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://www.haungrd.top">Huang RD</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://www.haungrd.top/2023/06/13/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/">http://www.haungrd.top/2023/06/13/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://www.haungrd.top" target="_blank">Huang Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/">微服务</a><a class="post-meta__tags" href="/tags/%E6%A1%86%E6%9E%B6/">框架</a><a class="post-meta__tags" href="/tags/Spring-Cloud/">Spring Cloud</a><a class="post-meta__tags" href="/tags/Nacos/">Nacos</a><a class="post-meta__tags" href="/tags/Seta/">Seta</a><a class="post-meta__tags" href="/tags/Gateway/">Gateway</a></div><div class="post_share"><div class="social-share" data-image="https://www.huangrd.top/images/agentina/12.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/07/31/%E7%AE%97%E6%B3%95%E7%AF%87-%E6%A8%A1%E6%8B%9F-%E8%AE%BE%E8%AE%A1/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/2.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">算法篇-模拟&amp;设计</div></div></a></div><div class="next-post pull-right"><a href="/2023/06/09/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%80%83%E8%AF%95/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/14.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">操作系统考试</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/12/16/SpringCloud01/" title="Spring Cloud 第一天"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-16</div><div class="title">Spring Cloud 第一天</div></div></a></div><div><a href="/2022/12/21/SpringCloud02/" title="Spring Cloud 第二天"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/5.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-21</div><div class="title">Spring Cloud 第二天</div></div></a></div><div><a href="/2022/12/26/RabbitMQ1/" title="RabbitMQ微服务复习"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/5.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-26</div><div class="title">RabbitMQ微服务复习</div></div></a></div><div><a href="/2022/12/28/%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E01/" title="分布式搜索引擎ElasticSearch1"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/1.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-28</div><div class="title">分布式搜索引擎ElasticSearch1</div></div></a></div><div><a href="/2023/01/03/%E5%88%86%E5%B8%83%E5%BC%8F%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E02/" title="分布式搜索引擎ElasticSearch2"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/4.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-03</div><div class="title">分布式搜索引擎ElasticSearch2</div></div></a></div><div><a href="/2022/12/24/Docker%E5%AE%9E%E7%94%A8%E7%AF%87/" title="Docker"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://www.huangrd.top/images/agentina/11.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-12-24</div><div class="title">Docker</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%A4%8D%E4%B9%A0%E6%8F%90%E5%8D%87"><span class="toc-text">微服务复习提升</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BE%AE%E6%9C%8D%E5%8A%A1"><span class="toc-text">微服务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81SpringCloud%E5%B8%B8%E8%A7%81%E7%BB%84%E4%BB%B6%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-text">1、SpringCloud常见组件有哪些？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81Nacos%E7%9A%84%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E8%A1%A8%E7%BB%93%E6%9E%84%E6%98%AF%E6%80%8E%E4%B9%88%E6%A0%B7%E7%9A%84%EF%BC%9F"><span class="toc-text">2、Nacos的服务注册表结构是怎么样的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81Nacos%E5%A6%82%E4%BD%95%E6%94%AF%E6%92%91%E9%98%BF%E9%87%8C%E5%86%85%E9%83%A8%E6%95%B0%E5%8D%81%E4%B8%87%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%8E%8B%E5%8A%9B%EF%BC%9F"><span class="toc-text">3、Nacos如何支撑阿里内部数十万服务注册压力？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%E3%80%81Nacos%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E5%B9%B6%E5%8F%91%E8%AF%BB%E5%86%99%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-text">4、Nacos如何避免并发读写冲突问题？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5%E3%80%81Nacos-%E5%92%8C-Eureka-%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-text">5、Nacos 和 Eureka 的区别？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6%E3%80%81Sentinel-%E7%9A%84%E9%99%90%E6%B5%81%E5%92%8C-Gateway-%E7%9A%84%E9%99%90%E6%B5%81%E6%9C%89%E4%BB%80%E4%B9%88%E5%B7%AE%E5%88%AB%EF%BC%9F"><span class="toc-text">6、Sentinel 的限流和 Gateway 的限流有什么差别？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7%E3%80%81Sentinel%E7%9A%84%E7%BA%BF%E7%A8%8B%E9%9A%94%E7%A6%BB%E4%B8%8E-Hystix-%E7%9A%84%E7%BA%BF%E7%A8%8B%E9%9A%94%E7%A6%BB%E6%9C%89%E4%BB%80%E4%B9%88%E5%B7%AE%E5%88%AB"><span class="toc-text">7、Sentinel的线程隔离与 Hystix 的线程隔离有什么差别?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8%E3%80%81%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%92%8C%E5%8F%91%E7%8E%B0%E6%98%AF%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D%EF%BC%9FSpring-Cloud-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E5%8F%91%E7%8E%B0%EF%BC%9F"><span class="toc-text">8、服务注册和发现是什么意思？Spring Cloud 如何实现服务注册发现？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9%E3%80%81Nacos-%E5%92%8C-Eureka-%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-text">9、Nacos 和 Eureka 有什么区别？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10%E3%80%81%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F"><span class="toc-text">10、项目的负载均衡是如何实现的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11%E3%80%81%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%8D%E5%8A%A1%E9%9B%AA%E5%B4%A9%EF%BC%8C%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-text">11、什么是服务雪崩，怎么解决这个问题？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12%E3%80%81%E4%BD%A0%E4%BB%AC%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%98%AF%E6%80%8E%E4%B9%88%E7%9B%91%E6%8E%A7%E7%9A%84%EF%BC%9F"><span class="toc-text">12、你们的微服务是怎么监控的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13%E3%80%81%E8%A7%A3%E9%87%8A%E4%B8%80%E4%B8%8B-CAP-%E5%92%8C-BASE"><span class="toc-text">13、解释一下 CAP 和 BASE</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14%E3%80%81%E4%BD%A0%E4%BB%AC%E4%BD%BF%E7%94%A8%E9%82%A3%E7%A7%8D%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9F"><span class="toc-text">14、你们使用那种分布式事务解决方案？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15%E3%80%81%E5%88%86%E5%B8%83%E5%BC%8F%E6%9C%8D%E5%8A%A1%E7%9A%84%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E6%80%A7%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%EF%BC%9F"><span class="toc-text">15、分布式服务的接口幂等性如何设计？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16%E3%80%81%E9%A1%B9%E7%9B%AE%E7%94%A8%E5%88%B0%E4%BA%86%E4%BB%80%E4%B9%88%E5%88%86%E5%B8%83%E5%BC%8F%E8%B0%83%E5%BA%A6%EF%BC%9F"><span class="toc-text">16、项目用到了什么分布式调度？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MQ-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="toc-text">MQ 消息队列</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81MQ-%E7%9A%84%E9%80%89%E5%9E%8B%E9%97%AE%E9%A2%98"><span class="toc-text">1、MQ 的选型问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81RabbitMQ-%E5%A6%82%E4%BD%95%E7%A1%AE%E4%BF%9D%E6%B6%88%E6%81%AF%E7%9A%84%E4%B8%8D%E4%B8%A2%E5%A4%B1%EF%BC%9F"><span class="toc-text">2、RabbitMQ 如何确保消息的不丢失？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81RabbitMQ-%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E6%B6%88%E6%81%AF%E5%A0%86%E7%A7%AF%EF%BC%9F"><span class="toc-text">3、RabbitMQ 如何避免消息堆积？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%E3%80%81RabbitMQ-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E7%9A%84%E6%9C%89%E5%BA%8F%E6%80%A7%EF%BC%9F"><span class="toc-text">4、RabbitMQ 如何保证消息的有序性？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5%E3%80%81%E5%A6%82%E4%BD%95%E9%98%B2%E6%AD%A2-MQ-%E6%B6%88%E6%81%AF%E8%A2%AB%E9%87%8D%E5%A4%8D%E6%B6%88%E8%B4%B9%EF%BC%9F"><span class="toc-text">5、如何防止 MQ 消息被重复消费？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6%E3%80%81%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81-RabbitMQ-%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%EF%BC%9F"><span class="toc-text">6、如何保证 RabbitMQ 的高可用？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7%E3%80%81%E4%BD%BF%E7%94%A8-MQ-%E5%8F%AF%E4%BB%A5%E8%A7%A3%E5%86%B3%E9%82%A3%E4%BA%9B%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="toc-text">7、使用 MQ 可以解决那些问题？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8%E3%80%81MQ-%E7%9A%84%E9%9B%86%E7%BE%A4%E4%BA%86%E8%A7%A3%E5%90%97%EF%BC%9F"><span class="toc-text">8、MQ 的集群了解吗？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9%E3%80%81RabbitMQ%E4%B8%AD%E6%AD%BB%E4%BF%A1%E4%BA%A4%E6%8D%A2%E6%9C%BA-RabbitMQ%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97%E6%9C%89%E4%BA%86%E8%A7%A3%E8%BF%87%E5%98%9B"><span class="toc-text">9、RabbitMQ中死信交换机 ? (RabbitMQ延迟队列有了解过嘛)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10%E3%80%81Kafka-%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1%EF%BC%9F"><span class="toc-text">10、Kafka 如何保证消息不丢失？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11%E3%80%81Kafka%E6%98%AF%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E8%B4%B9%E7%9A%84%E9%A1%BA%E5%BA%8F%E6%80%A7"><span class="toc-text">11、Kafka是如何保证消费的顺序性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12%E3%80%81Kafka%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9C%BA%E5%88%B6%E6%9C%89%E4%BA%86%E8%A7%A3%E8%BF%87%E5%98%9B"><span class="toc-text">12、Kafka的高可用机制有了解过嘛</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13%E3%80%81Kafka-%E6%95%B0%E6%8D%AE%E6%B8%85%E7%90%86%E6%9C%BA%E5%88%B6%E4%BA%86%E8%A7%A3%E8%BF%87%E5%98%9B"><span class="toc-text">13、Kafka 数据清理机制了解过嘛</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14%E3%80%81Kafka-%E4%B8%AD%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E8%AE%BE%E8%AE%A1%E6%9C%89%E4%BA%86%E8%A7%A3%E8%BF%87%E5%98%9B"><span class="toc-text">14、Kafka 中实现高性能的设计有了解过嘛</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Redis"><span class="toc-text">Redis</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1%E3%80%81Redis%E4%B8%8EMemcache%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%9F"><span class="toc-text">1、Redis与Memcache的区别？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2%E3%80%81Redis-%E7%9A%84%E5%8D%95%E7%BA%BF%E7%A8%8B%E9%97%AE%E9%A2%98"><span class="toc-text">2、Redis 的单线程问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81Redis-%E7%9A%84%E6%8C%81%E4%B9%85%E5%8C%96%E6%96%B9%E6%A1%88%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-text">3、Redis 的持久化方案有哪些？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3%E3%80%81Redis%E7%9A%84%E9%9B%86%E7%BE%A4%E6%96%B9%E5%BC%8F%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-text">3、Redis的集群方式有哪些？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4%E3%80%81Redis-%E7%9A%84%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E6%9C%89%E5%93%AA%E4%BA%9B%EF%BC%9F"><span class="toc-text">4、Redis 的常用数据类型有哪些？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5%E3%80%81%E8%81%8A%E4%B8%80%E4%B8%8B-Redis-%E4%BA%8B%E5%8A%A1%E6%9C%BA%E5%88%B6"><span class="toc-text">5、聊一下 Redis 事务机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6%E3%80%81Redis-%E7%9A%84-Key-%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5"><span class="toc-text">6、Redis 的 Key 过期策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%86%85%E5%AD%98%E5%9B%9E%E6%94%B6%EF%BC%9F"><span class="toc-text">为什么需要内存回收？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%87%E6%9C%9F%E5%88%A0%E9%99%A4%E7%AD%96%E7%95%A5"><span class="toc-text">过期删除策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5"><span class="toc-text">内存淘汰策略</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%A2%E8%AF%95%E8%AF%9D%E6%9C%AF%EF%BC%9A"><span class="toc-text">面试话术：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7%E3%80%81Redis%E5%9C%A8%E9%A1%B9%E7%9B%AE%E4%B8%AD%E7%9A%84%E5%93%AA%E4%BA%9B%E5%9C%B0%E6%96%B9%E6%9C%89%E7%94%A8%E5%88%B0"><span class="toc-text">7、Redis在项目中的哪些地方有用到?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8%E3%80%81Redis-%E7%9A%84%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E3%80%81%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F"><span class="toc-text">8、Redis 的缓存击穿、缓存雪崩、缓存穿透</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%EF%BC%89%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F"><span class="toc-text">1）缓存穿透</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%EF%BC%89%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF"><span class="toc-text">2）缓存击穿</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%EF%BC%89%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9"><span class="toc-text">3）缓存雪崩</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9%E3%80%81%E7%BC%93%E5%AD%98%E5%86%B7%E7%83%AD%E6%95%B0%E6%8D%AE%E5%88%86%E7%A6%BB"><span class="toc-text">9、缓存冷热数据分离</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10%E3%80%81Redis-%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-text">10、Redis 实现分布式锁</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1%EF%BC%89%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%9A"><span class="toc-text">1）最基本的分布式锁：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2%EF%BC%89%E5%8F%AF%E9%87%8D%E5%85%A5%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-text">2）可重入分布式锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3%EF%BC%89%E9%AB%98%E5%8F%AF%E7%94%A8%E7%9A%84%E9%94%81"><span class="toc-text">3）高可用的锁</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11%E3%80%81%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E7%BC%93%E5%AD%98%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%EF%BC%9F"><span class="toc-text">11、如何实现数据库与缓存数据一致？</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2023 By Huang RD</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="30" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>